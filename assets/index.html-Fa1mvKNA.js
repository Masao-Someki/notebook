import{_ as s,r,o as l,c as a,a as e,b as t,d as o}from"./app-FOR18dDf.js";const i={},d=e("h2",{id:"espnet2",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#espnet2"},[e("span",null,"ESPnet2")])],-1),h=e("h3",{id:"asr",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#asr"},[e("span",null,"ASR")])],-1),_=e("thead",null,[e("tr",null,[e("th",null,"Notebooks"),e("th",null,"Description")])],-1),u={href:"/espnet2/asr/asr_cli",target:"_blank",rel:"noopener noreferrer"},c=e("td",null,"This example shows you a practical ASR example using ESPnet as a command line interface, and also as a library.",-1),p={href:"/espnet2/asr/asr_library",target:"_blank",rel:"noopener noreferrer"},f=e("td",null,"This example shows you a practical ASR example using ESPnet as a command line interface and library.",-1),m={href:"/espnet2/asr/espnet2_asr_realtime_demo",target:"_blank",rel:"noopener noreferrer"},S=e("td",null,"This notebook provides a demonstration of the realtime E2E-ASR using ESPnet2-ASR.",-1),b={href:"/espnet2/asr/espnet2_asr_transfer_learning_demo",target:"_blank",rel:"noopener noreferrer"},g=e("td",null,"In that tutorial, we will introduce several options to use pre-trained models/parameters for Automatic Speech Recognition (ASR) in ESPnet2.",-1),k={href:"/espnet2/asr/espnet2_streaming_asr_demo",target:"_blank",rel:"noopener noreferrer"},E=e("td",null,"This local notebook provides a demonstration of streaming ASR based on Transformer using ESPnet2.",-1),T=e("h3",{id:"tts",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#tts"},[e("span",null,"TTS")])],-1),w=e("thead",null,[e("tr",null,[e("th",null,"Notebooks"),e("th",null,"Description")])],-1),P={href:"/espnet2/tts/espnet2_tts_realtime_demo",target:"_blank",rel:"noopener noreferrer"},x=e("td",null,"This notebook provides a demonstration of the realtime E2E-TTS using ESPnet2-TTS and ParallelWaveGAN repo.",-1),y={href:"/espnet2/tts/tts_cli",target:"_blank",rel:"noopener noreferrer"},A=e("td",null,"This is the example notebook of how-to-run the ESPnet TTS recipe using an4 dataset.",-1),U={href:"/espnet2/tts/tts_realtime_demo",target:"_blank",rel:"noopener noreferrer"},M=e("td",null,"This notebook provides a demonstration of the realtime E2E-TTS using ESPnet-TTS and ParallelWaveGAN (+ MelGAN).",-1),R=e("h3",{id:"se",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#se"},[e("span",null,"SE")])],-1),N=e("thead",null,[e("tr",null,[e("th",null,"Notebooks"),e("th",null,"Description")])],-1),v={href:"/espnet2/se/se_demo",target:"_blank",rel:"noopener noreferrer"},C=e("td",null,"This notebook provides a demonstration of the speech enhancement and separation using ESPnet2-SE.",-1),D={href:"/espnet2/se/espnet_se_demonstration_for_waspaa_2021",target:"_blank",rel:"noopener noreferrer"},L=e("td",null,"This notebook provides a demonstration of the speech enhancement and separation using ESPnet2-SE.",-1),I=e("h3",{id:"slu",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#slu"},[e("span",null,"SLU")])],-1),z=e("thead",null,[e("tr",null,[e("th",null,"Notebooks"),e("th",null,"Description")])],-1),F={href:"/espnet2/slu/espnet2_2pass_slu_demo",target:"_blank",rel:"noopener noreferrer"},O=e("td",null,"This notebook provides a demonstration of the Two Pass End-to-End Spoken Language Understanding model",-1),W=e("h3",{id:"st",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#st"},[e("span",null,"ST")])],-1),B=e("thead",null,[e("tr",null,[e("th",null,"Notebooks"),e("th",null,"Description")])],-1),G={href:"/espnet2/st/st_demo",target:"_blank",rel:"noopener noreferrer"},V=e("td",null,"This notebook provides a demonstration of the ST model using ESPnet.",-1),J=e("h3",{id:"others",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#others"},[e("span",null,"Others")])],-1),j=e("thead",null,[e("tr",null,[e("th",null,"Notebooks"),e("th",null,"Description")])],-1),q={href:"/espnet2/others/pretrained",target:"_blank",rel:"noopener noreferrer"},H=e("td",null,"This is the example notebook of how-to-recognize and -synthesize speech using the ESPnet models.",-1),K={href:"/espnet2/others/onnx_conversion_demo",target:"_blank",rel:"noopener noreferrer"},Q=e("td",null,"This notebook provides a demonstration of how to export your trained model into onnx format.",-1),X=e("h2",{id:"tutorials",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#tutorials"},[e("span",null,"Tutorials")])],-1),Y=e("thead",null,[e("tr",null,[e("th",null,"Notebooks"),e("th",null,"Description")])],-1),Z={href:"/tutorials/DataPreparation_CMU_11492_692_Spring2023(Assignment0)",target:"_blank",rel:"noopener noreferrer"},$=e("td",null,"In this demonstration, we will show you the procedure to prepare the data for speech processing (ASR as an example).",-1),ee={href:"/tutorials/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022",target:"_blank",rel:"noopener noreferrer"},te=e("td",null,"This tutorial shows how to add new task, new models, and create a new recipe.",-1),ne={href:"/tutorials/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022",target:"_blank",rel:"noopener noreferrer"},oe=e("td",null,"This tutorial shows how to run existing recipes, change the training and decoding configurations and create a new recipe, and where to find resources if you encounter an issue.",-1),se={href:"/tutorials/espnet2_tutorial_2021_CMU_11751_18781",target:"_blank",rel:"noopener noreferrer"},re=e("td",null,"This is a collection of espnet notebook demos",-1),le={href:"/tutorials/SpeechEnhancement_CMU_11492_692_Spring2023(Assignment7)",target:"_blank",rel:"noopener noreferrer"},ae=e("td",null,"In this demonstration, we will show you some demonstrations of speech enhancement systems in ESPnet.",-1),ie={href:"/tutorials/SpokenLanguageUnderstanding_CMU_11492_692_Spring2023(Assignment6)",target:"_blank",rel:"noopener noreferrer"},de=e("td",null,"In this demonstration, we will show you the procedure to conduct spoken language understanding in ESPnet.",-1),he={href:"/tutorials/TextToSpeech_CMU_11492_692_Spring2023(Assignment8)",target:"_blank",rel:"noopener noreferrer"},_e=e("td",null,"In this demonstration, we will show you some demonstrations of text to speech systems in ESPnet.",-1),ue=e("h2",{id:"espneteasy",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#espneteasy"},[e("span",null,"ESPnetEasy")])],-1),ce=e("p",null,"The following notebooks shows how to train/finetune the pretrained models with ESpnetEasy.",-1),pe=e("p",null,[e("strong",null,"ASR")],-1),fe=e("thead",null,[e("tr",null,[e("th",null,"Notebooks"),e("th",null,"Description")])],-1),me={href:"/espnetez/asr/train",target:"_blank",rel:"noopener noreferrer"},Se=e("td",null,"This notebook shows how to train an Automatic Speech Recognition (ASR) model using the Librispeech-100 dataset.",-1),be={href:"/espnetez/asr/finetune_with_lora",target:"_blank",rel:"noopener noreferrer"},ge=e("td",null,"This notebook shows the process of finetuning a pretrained model with LORA.",-1),ke={href:"/espnetez/asr/finetune_owsm",target:"_blank",rel:"noopener noreferrer"},Ee=e("td",null,[t("This notebook shows how to finetune the OWSM models usin custom dataset, "),e("code",null,"datasets"),t(" library, and "),e("code",null,"lhotse"),t(" library.")],-1),Te=e("p",null,[e("strong",null,"TTS")],-1),we=e("thead",null,[e("tr",null,[e("th",null,"Notebooks"),e("th",null,"Description")])],-1),Pe={href:"/espnetez/tts/tacotron2",target:"_blank",rel:"noopener noreferrer"},xe=e("td",null,"This notebook shows how to train an Text to Speech (TTS) model using the LJSpeech dataset.",-1);function ye(Ae,Ue){const n=r("ExternalLinkIcon");return l(),a("div",null,[d,h,e("table",null,[_,e("tbody",null,[e("tr",null,[e("td",null,[e("a",u,[t("Speech Recognition (Recipe)"),o(n)])]),c]),e("tr",null,[e("td",null,[e("a",p,[t("Speech Recognition (Library)"),o(n)])]),f]),e("tr",null,[e("td",null,[e("a",m,[t("ESPnet2-ASR realtime demonstration"),o(n)])]),S]),e("tr",null,[e("td",null,[e("a",b,[t("Use transfer learning for ASR in ESPnet2"),o(n)])]),g]),e("tr",null,[e("td",null,[e("a",k,[t("ESPnet2 real streaming Transformer demonstration"),o(n)])]),E])])]),T,e("table",null,[w,e("tbody",null,[e("tr",null,[e("td",null,[e("a",P,[t("ESPnet2-TTS realtime demonstration"),o(n)])]),x]),e("tr",null,[e("td",null,[e("a",y,[t("Text-to-Speech (Recipe)"),o(n)])]),A]),e("tr",null,[e("td",null,[e("a",U,[t("ESPnet real time E2E-TTS demonstration"),o(n)])]),M])])]),R,e("table",null,[N,e("tbody",null,[e("tr",null,[e("td",null,[e("a",v,[t("ESPnet Speech Enhancement Demonstration"),o(n)])]),C]),e("tr",null,[e("td",null,[e("a",D,[t("ESPnet Speech Enhancement Demonstration"),o(n)])]),L])])]),I,e("table",null,[z,e("tbody",null,[e("tr",null,[e("td",null,[e("a",F,[t("ESPNET 2 pass SLU Demonstration"),o(n)])]),O])])]),W,e("table",null,[B,e("tbody",null,[e("tr",null,[e("td",null,[e("a",G,[t("ESPNET 2 pass SLU Demonstration"),o(n)])]),V])])]),J,e("table",null,[j,e("tbody",null,[e("tr",null,[e("td",null,[e("a",q,[t("Pretrained Model"),o(n)])]),H]),e("tr",null,[e("td",null,[e("a",K,[t("espnet_onnx demonstration"),o(n)])]),Q])])]),X,e("table",null,[Y,e("tbody",null,[e("tr",null,[e("td",null,[e("a",Z,[t("CMU 11492/11692 Spring 2023: Data preparation"),o(n)])]),$]),e("tr",null,[e("td",null,[e("a",ee,[t("CMU 11751/18781 Fall 2022: ESPnet Tutorial2 (New task)"),o(n)])]),te]),e("tr",null,[e("td",null,[e("a",ne,[t("CMU 11751/18781 Fall 2022: ESPnet Tutorial"),o(n)])]),oe]),e("tr",null,[e("td",null,[e("a",se,[t("CMU 11751/18781 2021: ESPnet Tutorial"),o(n)])]),re]),e("tr",null,[e("td",null,[e("a",le,[t("CMU 11492/11692 Spring 2023: Speech Enhancement"),o(n)])]),ae]),e("tr",null,[e("td",null,[e("a",ie,[t("CMU 11492/11692 Spring 2023: Spoken Language Understanding"),o(n)])]),de]),e("tr",null,[e("td",null,[e("a",he,[t("CMU 11492/11692 Spring 2023: Text to Speech"),o(n)])]),_e])])]),ue,ce,pe,e("table",null,[fe,e("tbody",null,[e("tr",null,[e("td",null,[e("a",me,[t("Sample demo for ESPnet-Easy!"),o(n)])]),Se]),e("tr",null,[e("td",null,[e("a",be,[t("Finetune Model with ESPnet-Easy"),o(n)])]),ge]),e("tr",null,[e("td",null,[e("a",ke,[t("OWSM finetuning with custom dataset"),o(n)])]),Ee])])]),Te,e("table",null,[we,e("tbody",null,[e("tr",null,[e("td",null,[e("a",Pe,[t("TTS demo for ESPnet-Easy!"),o(n)])]),xe])])])])}const Re=s(i,[["render",ye],["__file","index.html.vue"]]);export{Re as default};
