import{_ as e,r as l,o as p,c as o,a as s,b as n,d as i,e as t}from"./app-FOR18dDf.js";const r={},c=s("h1",{id:"sample-demo-for-espnet-easy",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#sample-demo-for-espnet-easy"},[s("span",null,"Sample demo for ESPnet-Easy!")])],-1),d=s("p",null,"In this notebook, we will demonstrate how to train an Automatic Speech Recognition (ASR) model using the Librispeech-100 dataset. The process in this notebook follows the same dataset preparation approach as the kaldi-style dataset. If you are interested in fine-tuning pretrained models, please refer to the libri100_finetune.ipynb file.",-1),D={href:"https://www.openslr.org/12",target:"_blank",rel:"noopener noreferrer"},u=s("code",null,"/hdd/dataset/",-1),y=s("code",null,"/hdd/dataset/",-1),v=t(`<h2 id="data-preparation" tabindex="-1"><a class="header-anchor" href="#data-preparation"><span>Data Preparation</span></a></h2><p>This notebook follows the data preparation steps outlined in <code>asr.sh</code>. Initially, we will create a dump file to store information about the data, including the data ID, audio path, and transcriptions.</p><p>ESPnet-Easy supports various types of datasets, including:</p><ol><li><p>Dictionary-based dataset with the following structure:</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#D4D4D4;">{</span></span>
<span class="line"><span style="color:#CE9178;">  &quot;data_id&quot;</span><span style="color:#D4D4D4;">: {</span></span>
<span class="line"><span style="color:#CE9178;">      &quot;speech&quot;</span><span style="color:#D4D4D4;">: path_to_speech_file,</span></span>
<span class="line"><span style="color:#CE9178;">      &quot;text&quot;</span><span style="color:#D4D4D4;">: transcription</span></span>
<span class="line"><span style="color:#D4D4D4;">  }</span></span>
<span class="line"><span style="color:#D4D4D4;">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>List of datasets with the following structure:</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#D4D4D4;">[</span></span>
<span class="line"><span style="color:#D4D4D4;">  {</span></span>
<span class="line"><span style="color:#CE9178;">      &quot;speech&quot;</span><span style="color:#D4D4D4;">: path_to_speech_file,</span></span>
<span class="line"><span style="color:#CE9178;">      &quot;text&quot;</span><span style="color:#D4D4D4;">: transcription</span></span>
<span class="line"><span style="color:#D4D4D4;">  }</span></span>
<span class="line"><span style="color:#D4D4D4;">]</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol><p>If you choose to use a dictionary-based dataset, it&#39;s essential to ensure that each <code>data_id</code> is unique. ESPnet-Easy also accepts a dump file that may have already been created by <code>asr.sh</code>. However, in this notebook, we will create the dump file from scratch.</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#6A9955;"># Need to install espnet if you don&#39;t have it</span></span>
<span class="line"><span style="color:#D4D4D4;">%pip install -U espnet</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>Now, let&#39;s create dump files!<br> Please note that you will need to provide a dictionary to specify the file path and type for each data. This dictionary should have the following format:</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#D4D4D4;">{</span></span>
<span class="line"><span style="color:#CE9178;">    &quot;data_name&quot;</span><span style="color:#D4D4D4;">: [</span><span style="color:#CE9178;">&quot;dump_file_name&quot;</span><span style="color:#D4D4D4;">, </span><span style="color:#CE9178;">&quot;dump_format&quot;</span><span style="color:#D4D4D4;">]</span></span>
<span class="line"><span style="color:#D4D4D4;">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> os</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> espnetez </span><span style="color:#C586C0;">as</span><span style="color:#D4D4D4;"> ez</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C586C0;">from</span><span style="color:#D4D4D4;"> local.data_prep </span><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> create_dataset</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#D4D4D4;">DUMP_DIR = </span><span style="color:#CE9178;">&quot;./dump/libri100&quot;</span></span>
<span class="line"><span style="color:#D4D4D4;">LIBRI_100_DIRS = [</span></span>
<span class="line"><span style="color:#D4D4D4;">    [</span><span style="color:#CE9178;">&quot;/hdd/database/librispeech-100/LibriSpeech/train-clean-100&quot;</span><span style="color:#D4D4D4;">, </span><span style="color:#CE9178;">&quot;train&quot;</span><span style="color:#D4D4D4;">],</span></span>
<span class="line"><span style="color:#D4D4D4;">    [</span><span style="color:#CE9178;">&quot;/hdd/database/librispeech-100/LibriSpeech/dev-clean&quot;</span><span style="color:#D4D4D4;">, </span><span style="color:#CE9178;">&quot;dev-clean&quot;</span><span style="color:#D4D4D4;">],</span></span>
<span class="line"><span style="color:#D4D4D4;">    [</span><span style="color:#CE9178;">&quot;/hdd/database/librispeech-100/LibriSpeech/dev-other&quot;</span><span style="color:#D4D4D4;">, </span><span style="color:#CE9178;">&quot;dev-other&quot;</span><span style="color:#D4D4D4;">],</span></span>
<span class="line"><span style="color:#D4D4D4;">]</span></span>
<span class="line"><span style="color:#D4D4D4;">data_info = {</span></span>
<span class="line"><span style="color:#CE9178;">    &quot;speech&quot;</span><span style="color:#D4D4D4;">: [</span><span style="color:#CE9178;">&quot;wav.scp&quot;</span><span style="color:#D4D4D4;">, </span><span style="color:#CE9178;">&quot;sound&quot;</span><span style="color:#D4D4D4;">],</span></span>
<span class="line"><span style="color:#CE9178;">    &quot;text&quot;</span><span style="color:#D4D4D4;">: [</span><span style="color:#CE9178;">&quot;text&quot;</span><span style="color:#D4D4D4;">, </span><span style="color:#CE9178;">&quot;text&quot;</span><span style="color:#D4D4D4;">],</span></span>
<span class="line"><span style="color:#D4D4D4;">}</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#C586C0;">for</span><span style="color:#D4D4D4;"> d, n </span><span style="color:#C586C0;">in</span><span style="color:#D4D4D4;"> LIBRI_100_DIRS:</span></span>
<span class="line"><span style="color:#D4D4D4;">    dump_dir = os.path.join(DUMP_DIR, n)</span></span>
<span class="line"><span style="color:#C586C0;">    if</span><span style="color:#569CD6;"> not</span><span style="color:#D4D4D4;"> os.path.exists(dump_dir):</span></span>
<span class="line"><span style="color:#D4D4D4;">        os.makedirs(dump_dir)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D4D4D4;">    dataset = create_dataset(d)</span></span>
<span class="line"><span style="color:#D4D4D4;">    ez.data.create_dump_file(dump_dir, dataset, data_info)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>For the validation files, you have two directories: <code>dev-clean</code> and <code>dev-other</code>. To create a unified dev dataset, you can use the <code>ez.data.join_dumps</code> function.</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#D4D4D4;">ez.data.join_dumps(</span></span>
<span class="line"><span style="color:#D4D4D4;">    [</span><span style="color:#CE9178;">&quot;./dump/libri100/dev-clean&quot;</span><span style="color:#D4D4D4;">, </span><span style="color:#CE9178;">&quot;./dump/libri100/dev-other&quot;</span><span style="color:#D4D4D4;">], </span><span style="color:#CE9178;">&quot;./dump/libri100/dev&quot;</span></span>
<span class="line"><span style="color:#D4D4D4;">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Now you have dataset files in the <code>dump</code> directory. It looks like this:</p><p>wav.scp</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>1255-138279-0008 /hdd/database/librispeech-100/LibriSpeech/dev-other/1255/138279/1255-138279-0008.flac</span></span>
<span class="line"><span>1255-138279-0022 /hdd/database/librispeech-100/LibriSpeech/dev-other/1255/138279/1255-138279-0022.flac</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>text</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>1255-138279-0008 TWO THREE</span></span>
<span class="line"><span>1255-138279-0022 IF I SAID SO OF COURSE I WILL</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="train-sentencepiece-model" tabindex="-1"><a class="header-anchor" href="#train-sentencepiece-model"><span>Train sentencepiece model</span></a></h2><p>To train a SentencePiece model, we require a text file for training. Let&#39;s begin by creating the training file.</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#6A9955;"># generate training texts from the training data</span></span>
<span class="line"><span style="color:#6A9955;"># you can select several datasets to train sentencepiece.</span></span>
<span class="line"><span style="color:#D4D4D4;">ez.preprocess.prepare_sentences([</span><span style="color:#CE9178;">&quot;dump/libri100/train/text&quot;</span><span style="color:#D4D4D4;">], </span><span style="color:#CE9178;">&quot;dump/spm&quot;</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D4D4D4;">ez.preprocess.train_sentencepiece(</span></span>
<span class="line"><span style="color:#CE9178;">    &quot;dump/spm/train.txt&quot;</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#CE9178;">    &quot;data/bpemodel&quot;</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#9CDCFE;">    vocab_size</span><span style="color:#D4D4D4;">=</span><span style="color:#B5CEA8;">5000</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#D4D4D4;">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="configure-training-process" tabindex="-1"><a class="header-anchor" href="#configure-training-process"><span>Configure Training Process</span></a></h2><p>For configuring the training process, you can utilize the configuration files already provided by ESPnet contributors. To use a configuration file, you&#39;ll need to create a YAML file on your local machine. For instance, you can use the <a href="train_asr_e-branchformer_size256_mlp1024_linear1024_e12_mactrue_edrop0.0_ddrop0.0.yaml">e-branchformer config</a>.</p><p>In my case, I&#39;ve made a modification to the <code>batch_bins</code> parameter, changing it from <code>16000000</code> to <code>1600000</code> to run training on my GPU (RTX2080ti).</p><h2 id="training" tabindex="-1"><a class="header-anchor" href="#training"><span>Training</span></a></h2><p>To prepare the stats file before training, you can execute the <code>collect_stats</code> method. This step is required before the training process and ensuring accurate statistics for the model.</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> espnetez </span><span style="color:#C586C0;">as</span><span style="color:#D4D4D4;"> ez</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D4D4D4;">EXP_DIR = </span><span style="color:#CE9178;">&quot;exp/train_asr_branchformer_e24_amp&quot;</span></span>
<span class="line"><span style="color:#D4D4D4;">STATS_DIR = </span><span style="color:#CE9178;">&quot;exp/stats&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A9955;"># load config</span></span>
<span class="line"><span style="color:#D4D4D4;">training_config = ez.config.from_yaml(</span></span>
<span class="line"><span style="color:#CE9178;">    &quot;asr&quot;</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#CE9178;">    &quot;config/train_asr_e_branchformer_size256_mlp1024_linear1024_e12_mactrue_edrop0.0_ddrop0.0.yaml&quot;</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#D4D4D4;">)</span></span>
<span class="line"><span style="color:#D4D4D4;">preprocessor_config = ez.utils.load_yaml(</span><span style="color:#CE9178;">&quot;config/preprocess.yaml&quot;</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"><span style="color:#D4D4D4;">training_config.update(preprocessor_config)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C586C0;">with</span><span style="color:#DCDCAA;"> open</span><span style="color:#D4D4D4;">(preprocessor_config[</span><span style="color:#CE9178;">&quot;token_list&quot;</span><span style="color:#D4D4D4;">], </span><span style="color:#CE9178;">&quot;r&quot;</span><span style="color:#D4D4D4;">) </span><span style="color:#C586C0;">as</span><span style="color:#D4D4D4;"> f:</span></span>
<span class="line"><span style="color:#D4D4D4;">    training_config[</span><span style="color:#CE9178;">&quot;token_list&quot;</span><span style="color:#D4D4D4;">] = [t.replace(</span><span style="color:#CE9178;">&quot;</span><span style="color:#D7BA7D;">\\n</span><span style="color:#CE9178;">&quot;</span><span style="color:#D4D4D4;">, </span><span style="color:#CE9178;">&quot;&quot;</span><span style="color:#D4D4D4;">) </span><span style="color:#C586C0;">for</span><span style="color:#D4D4D4;"> t </span><span style="color:#C586C0;">in</span><span style="color:#D4D4D4;"> f.readlines()]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A9955;"># Define the Trainer class</span></span>
<span class="line"><span style="color:#D4D4D4;">trainer = ez.Trainer(</span></span>
<span class="line"><span style="color:#9CDCFE;">    task</span><span style="color:#D4D4D4;">=</span><span style="color:#CE9178;">&#39;asr&#39;</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#9CDCFE;">    train_config</span><span style="color:#D4D4D4;">=training_config,</span></span>
<span class="line"><span style="color:#9CDCFE;">    train_dump_dir</span><span style="color:#D4D4D4;">=</span><span style="color:#CE9178;">&quot;dump/libri100/train&quot;</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#9CDCFE;">    valid_dump_dir</span><span style="color:#D4D4D4;">=</span><span style="color:#CE9178;">&quot;dump/libri100/dev&quot;</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#9CDCFE;">    data_info</span><span style="color:#D4D4D4;">=data_info,</span></span>
<span class="line"><span style="color:#9CDCFE;">    output_dir</span><span style="color:#D4D4D4;">=EXP_DIR,</span></span>
<span class="line"><span style="color:#9CDCFE;">    stats_dir</span><span style="color:#D4D4D4;">=STATS_DIR,</span></span>
<span class="line"><span style="color:#9CDCFE;">    ngpu</span><span style="color:#D4D4D4;">=</span><span style="color:#B5CEA8;">1</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#D4D4D4;">)</span></span>
<span class="line"><span style="color:#D4D4D4;">trainer.collect_stats()</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Finally, we are ready to begin the training process!</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#D4D4D4;">trainer.train()</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h2 id="inference" tabindex="-1"><a class="header-anchor" href="#inference"><span>Inference</span></a></h2><p>You can just use the inference API of the ESPnet.</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> librosa</span></span>
<span class="line"><span style="color:#C586C0;">from</span><span style="color:#D4D4D4;"> espnet2.bin.asr_inference </span><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> Speech2Text</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D4D4D4;">m = Speech2Text(</span></span>
<span class="line"><span style="color:#CE9178;">    &quot;./exp/train_asr_branchformer_e24_amp/config.yaml&quot;</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#CE9178;">	&quot;./exp/train_asr_branchformer_e24_amp/valid.acc.best.pth&quot;</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#9CDCFE;">	beam_size</span><span style="color:#D4D4D4;">=</span><span style="color:#B5CEA8;">10</span></span>
<span class="line"><span style="color:#D4D4D4;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C586C0;">with</span><span style="color:#DCDCAA;"> open</span><span style="color:#D4D4D4;">(</span><span style="color:#CE9178;">&quot;./dump/libri100/dev/wav.scp&quot;</span><span style="color:#D4D4D4;">, </span><span style="color:#CE9178;">&quot;r&quot;</span><span style="color:#D4D4D4;">) </span><span style="color:#C586C0;">as</span><span style="color:#D4D4D4;"> f:</span></span>
<span class="line"><span style="color:#D4D4D4;">    sample_path = f.readlines()[</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">]</span></span>
<span class="line"><span style="color:#D4D4D4;">    </span></span>
<span class="line"><span style="color:#D4D4D4;">y, sr = librosa.load(sample_path.split()[</span><span style="color:#B5CEA8;">1</span><span style="color:#D4D4D4;">], </span><span style="color:#9CDCFE;">sr</span><span style="color:#D4D4D4;">=</span><span style="color:#B5CEA8;">16000</span><span style="color:#D4D4D4;">, </span><span style="color:#9CDCFE;">mono</span><span style="color:#D4D4D4;">=</span><span style="color:#569CD6;">True</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"><span style="color:#D4D4D4;">output = m(y)</span></span>
<span class="line"><span style="color:#DCDCAA;">print</span><span style="color:#D4D4D4;">(output[</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">][</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">])</span></span>
<span class="line"></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,30);function m(b,h){const a=l("ExternalLinkIcon");return p(),o("div",null,[c,d,s("p",null,[n("Before proceeding, please ensure that you have already downloaded the Librispeech-100 dataset from "),s("a",D,[n("OpenSLR"),i(a)]),n(" and have placed the data in a directory of your choice. In this notebook, we assume that you have stored the dataset in the "),u,n(" directory. If your dataset is located in a different directory, please make sure to replace "),y,n(" with the actual path to your dataset.")]),v])}const _=e(r,[["render",m],["__file","train.html.vue"]]);export{_ as default};
