import{_ as t,r as l,o as p,c as d,a as e,b as s,d as a,e as i}from"./app-FOR18dDf.js";const c={},o=e("h1",{id:"pretrained-model",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#pretrained-model"},[e("span",null,"Pretrained Model")])],-1),r=e("p",null,"This is the example notebook of how-to-recognize and -synthesize speech using the ESPnet models.",-1),u=e("p",null,"See also:",-1),m=e("ul",null,[e("li",null,"Tutorial: https://github.com/espnet/espnet/blob/master/doc/tutorial.md"),e("li",null,"Github: https://github.com/espnet")],-1),h={href:"https://github.com/takenori-y",target:"_blank",rel:"noopener noreferrer"},v=i(`<p>Last update: 2019/07/28</p><h2 id="setup-envrionment" tabindex="-1"><a class="header-anchor" href="#setup-envrionment"><span>Setup envrionment</span></a></h2><p>Let&#39;s setup the environmet for the demonstration. It takes around 10 minues. Please keep waiting for a while.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span># OS setup</span></span>
<span class="line"><span>!sudo apt-get install bc tree sox</span></span>
<span class="line"><span>!cat /etc/os-release</span></span>
<span class="line"><span></span></span>
<span class="line"><span># espnet setup</span></span>
<span class="line"><span>!git clone https://github.com/espnet/espnet</span></span>
<span class="line"><span>!cd espnet; pip install -e .</span></span>
<span class="line"><span></span></span>
<span class="line"><span># warp ctc setup</span></span>
<span class="line"><span>!git clone https://github.com/espnet/warp-ctc -b pytorch-1.1</span></span>
<span class="line"><span>!cd warp-ctc &amp;&amp; mkdir build &amp;&amp; cd build &amp;&amp; cmake .. &amp;&amp; make -j</span></span>
<span class="line"><span>!cd warp-ctc/pytorch_binding &amp;&amp; python setup.py install </span></span>
<span class="line"><span></span></span>
<span class="line"><span># kaldi setup</span></span>
<span class="line"><span>!cd /content/espnet/tools; git clone https://github.com/kaldi-asr/kaldi</span></span>
<span class="line"><span>!echo &quot;&quot; &gt; ./espnet/tools/kaldi/tools/extras/check_dependencies.sh</span></span>
<span class="line"><span>!chmod +x ./espnet/tools/kaldi/tools/extras/check_dependencies.sh</span></span>
<span class="line"><span>!cd ./espnet/tools/kaldi/tools; make sph2pipe sclite</span></span>
<span class="line"><span>!rm -rf espnet/tools/kaldi/tools/python</span></span>
<span class="line"><span>!wget https://18-198329952-gh.circle-artifacts.com/0/home/circleci/repo/ubuntu16-featbin.tar.gz</span></span>
<span class="line"><span>!tar -xf ./ubuntu16-featbin.tar.gz</span></span>
<span class="line"><span>!cp featbin/* espnet/tools/kaldi/src/featbin/</span></span>
<span class="line"><span></span></span>
<span class="line"><span># sentencepiece setup</span></span>
<span class="line"><span>!cd espnet/tools; make sentencepiece.done</span></span>
<span class="line"><span></span></span>
<span class="line"><span># make dummy activate</span></span>
<span class="line"><span>!mkdir -p espnet/tools/venv/bin</span></span>
<span class="line"><span>!touch espnet/tools/venv/bin/activate</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="recognize-speech-using-pretrained-models" tabindex="-1"><a class="header-anchor" href="#recognize-speech-using-pretrained-models"><span>Recognize speech using pretrained models</span></a></h2><p>Let&#39;s recognize 7-minutes long audio speech as an example. Go to a recipe directory and run <code>recog_wav.sh</code> at the directory.</p>`,6),b={href:"https://github.com/espnet/espnet#asr-demo",target:"_blank",rel:"noopener noreferrer"},g=i(`<div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!cd espnet/egs/tedlium2/asr1; bash ../../../utils/recog_wav.sh --models tedlium2.tacotron2.v1</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>You can see the progress of the recognition.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!cat espnet/egs/tedlium2/asr1/decode/TomWujec_2010U/log/decode.log</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>You can change E2E model, language model, decoding parameters, etc. For the detail, see <code>recog_wav.sh</code>.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!cat espnet/utils/recog_wav.sh</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h2 id="synthesize-speech-using-pretrained-models" tabindex="-1"><a class="header-anchor" href="#synthesize-speech-using-pretrained-models"><span>Synthesize speech using pretrained models</span></a></h2><p>Let&#39;s synthesize speech using an E2E model. Go to a recipe directory and run <code>synth_wav.sh</code> at the directory.</p>`,7),x={href:"https://github.com/espnet/espnet#tts-demo",target:"_blank",rel:"noopener noreferrer"},k=i(`<div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!cd espnet/egs/ljspeech/tts1; \\</span></span>
<span class="line"><span>echo &quot;THIS IS A DEMONSTRATION OF TEXT TO SPEECH.&quot; &gt; example.txt; \\</span></span>
<span class="line"><span>bash ../../../utils/synth_wav.sh --models ljspeech.tacotron2.v1 example.txt</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Let&#39;s listen the synthesized speech!</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>from google.colab import files</span></span>
<span class="line"><span></span></span>
<span class="line"><span>files.download(&#39;espnet/egs/ljspeech/tts1/decode/example/wav/example.wav&#39;)</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>You can change E2E model, decoding parameters, etc. For the detail, see <code>synth_wav.sh</code>.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!cat espnet/utils/synth_wav.sh</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>We have a web storage to put your good trained models. If you want, please contact Shinji Watanabe <a href="mailto:shinjiw@ieee.org">shinjiw@ieee.org</a>.</p>`,6);function _(E,f){const n=l("ExternalLinkIcon");return p(),d("div",null,[o,r,u,m,e("p",null,[s("Author: "),e("a",h,[s("Takenori Yoshimura"),a(n)])]),v,e("p",null,[s("Available models are summarized "),e("a",b,[s("here"),a(n)]),s(".")]),g,e("p",null,[s("Available models are summarized "),e("a",x,[s("here"),a(n)]),s(".")]),k])}const w=t(c,[["render",_],["__file","pretrained.html.vue"]]);export{w as default};
