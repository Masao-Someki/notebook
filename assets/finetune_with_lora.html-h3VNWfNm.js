import{_ as s,o as n,c as a,e}from"./app-FOR18dDf.js";const l={},i=e(`<h1 id="finetune-model-with-espnet-easy" tabindex="-1"><a class="header-anchor" href="#finetune-model-with-espnet-easy"><span>Finetune Model with ESPnet-Easy</span></a></h1><p>In this notebook, we will explore the process of finetuning a pretrained model using the Librispeech-100 dataset. We&#39;ll start by downloading a pretrained model from the Hugging Face model hub and apply Low-Rank Adaptation (LoRA) techniques to reduce the number of training parameters.</p><p>In this notebook, we assume that the dump files have been already created. If you need guidance on creating the dump files, you can refer to the <code>training.ipynb</code> notebook.</p><p>First, we need to install the <code>loralib</code> package.</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#D4D4D4;">%pip install loralib</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>As with the <code>training.ipynb</code> notebook, we need to provide a dictionary to specify the file path and type for each data.</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#D4D4D4;">DUMP_DIR = </span><span style="color:#CE9178;">&quot;./dump/libri100&quot;</span></span>
<span class="line"><span style="color:#D4D4D4;">data_info = {</span></span>
<span class="line"><span style="color:#CE9178;">    &quot;speech&quot;</span><span style="color:#D4D4D4;">: [</span><span style="color:#CE9178;">&quot;wav.scp&quot;</span><span style="color:#D4D4D4;">, </span><span style="color:#CE9178;">&quot;sound&quot;</span><span style="color:#D4D4D4;">],</span></span>
<span class="line"><span style="color:#CE9178;">    &quot;text&quot;</span><span style="color:#D4D4D4;">: [</span><span style="color:#CE9178;">&quot;text&quot;</span><span style="color:#D4D4D4;">, </span><span style="color:#CE9178;">&quot;text&quot;</span><span style="color:#D4D4D4;">],</span></span>
<span class="line"><span style="color:#D4D4D4;">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="load-a-pretrained-model" tabindex="-1"><a class="header-anchor" href="#load-a-pretrained-model"><span>Load a pretrained model</span></a></h2><p>In ESPnet-Easy, you have the flexibility to define a custom model using the <code>build_model_fn</code> method. Additionally, you can load a pretrained model when needed.</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#C586C0;">from</span><span style="color:#D4D4D4;"> espnet2.bin.asr_inference </span><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> Speech2Text</span></span>
<span class="line"><span style="color:#C586C0;">from</span><span style="color:#D4D4D4;"> espnet2.layers.create_lora_adapter </span><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> create_lora_adapter</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#569CD6;">def</span><span style="color:#DCDCAA;"> build_model_fn</span><span style="color:#D4D4D4;">(</span><span style="color:#9CDCFE;">args</span><span style="color:#D4D4D4;">):</span></span>
<span class="line"><span style="color:#D4D4D4;">    pretrained_model = Speech2Text.from_pretrained(</span><span style="color:#CE9178;">&#39;pyf98/librispeech_conformer_hop_length160&#39;</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"><span style="color:#D4D4D4;">    model = pretrained_model.asr_model</span></span>
<span class="line"><span style="color:#D4D4D4;">    model.train()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A9955;">    # apply lora</span></span>
<span class="line"><span style="color:#D4D4D4;">    create_lora_adapter(model, </span><span style="color:#9CDCFE;">target_modules</span><span style="color:#D4D4D4;">=[</span><span style="color:#CE9178;">&#39;linear_q&#39;</span><span style="color:#D4D4D4;">])</span></span>
<span class="line"><span style="color:#C586C0;">    return</span><span style="color:#D4D4D4;"> model</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>When working with a pretrained model, the configuration is inherited from the model by default. To activate the LoRA model, it&#39;s essential to set the <code>use_lora</code> parameter to <code>True</code>. This configuration update can be easily achieved using the <code>update_finetune_config</code> method.</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> espnetez </span><span style="color:#C586C0;">as</span><span style="color:#D4D4D4;"> ez</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#D4D4D4;">pretrained_model = Speech2Text.from_pretrained(</span><span style="color:#CE9178;">&#39;pyf98/librispeech_conformer_hop_length160&#39;</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"><span style="color:#D4D4D4;">pretrain_config = </span><span style="color:#DCDCAA;">vars</span><span style="color:#D4D4D4;">(pretrained_model.asr_train_args)</span></span>
<span class="line"><span style="color:#C586C0;">del</span><span style="color:#D4D4D4;"> pretrained_model</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D4D4D4;">finetune_config = ez.config.update_finetune_config(</span></span>
<span class="line"><span style="color:#CE9178;">	&#39;asr&#39;</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#D4D4D4;">	pretrain_config,</span></span>
<span class="line"><span style="color:#CE9178;">	&#39;config/finetune_with_lora.yaml&#39;</span></span>
<span class="line"><span style="color:#D4D4D4;">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="training" tabindex="-1"><a class="header-anchor" href="#training"><span>Training</span></a></h2><p>Finally, let&#39;s start training.</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#D4D4D4;">EXP_DIR = </span><span style="color:#CE9178;">&quot;exp/finetune&quot;</span></span>
<span class="line"><span style="color:#D4D4D4;">STATS_DIR = </span><span style="color:#CE9178;">&quot;exp/stats_finetune&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D4D4D4;">trainer = ez.Trainer(</span></span>
<span class="line"><span style="color:#9CDCFE;">    task</span><span style="color:#D4D4D4;">=</span><span style="color:#CE9178;">&#39;asr&#39;</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#9CDCFE;">    train_config</span><span style="color:#D4D4D4;">=finetune_config,</span></span>
<span class="line"><span style="color:#9CDCFE;">    train_dump_dir</span><span style="color:#D4D4D4;">=</span><span style="color:#CE9178;">&quot;dump/libri100/train&quot;</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#9CDCFE;">    valid_dump_dir</span><span style="color:#D4D4D4;">=</span><span style="color:#CE9178;">&quot;dump/libri100/dev&quot;</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#9CDCFE;">    build_model_fn</span><span style="color:#D4D4D4;">=build_model_fn, </span><span style="color:#6A9955;"># provide the pre-trained model</span></span>
<span class="line"><span style="color:#9CDCFE;">    data_info</span><span style="color:#D4D4D4;">=data_info,</span></span>
<span class="line"><span style="color:#9CDCFE;">    output_dir</span><span style="color:#D4D4D4;">=EXP_DIR,</span></span>
<span class="line"><span style="color:#9CDCFE;">    stats_dir</span><span style="color:#D4D4D4;">=STATS_DIR,</span></span>
<span class="line"><span style="color:#9CDCFE;">    ngpu</span><span style="color:#D4D4D4;">=</span><span style="color:#B5CEA8;">1</span></span>
<span class="line"><span style="color:#D4D4D4;">)</span></span>
<span class="line"><span style="color:#D4D4D4;">trainer.collect_stats()</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#D4D4D4;">trainer.train()</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div>`,16),p=[i];function o(t,r){return n(),a("div",null,p)}const d=s(l,[["render",o],["__file","finetune_with_lora.html.vue"]]);export{d as default};
