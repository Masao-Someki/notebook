import{_ as a,r as l,o,c as p,a as s,b as n,d as i,e as t}from"./app-FOR18dDf.js";const r={},c=s("h1",{id:"espnet-onnx-demonstration",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#espnet-onnx-demonstration"},[s("span",null,"espnet_onnx demonstration")])],-1),d=s("p",null,"This notebook provides a demonstration of how to export your trained model into onnx format. Currently only ASR is supported.",-1),D=s("p",null,"see also:",-1),m=s("ul",null,[s("li",null,"ESPnet: https://github.com/espnet/espnet"),s("li",null,"espnet_onnx: https://github.com/Masao-Someki/espnet_onnx")],-1),v={href:"https://github.com/Masao-Someki",target:"_blank",rel:"noopener noreferrer"},y=t(`<h2 id="table-of-contents" tabindex="-1"><a class="header-anchor" href="#table-of-contents"><span>Table of Contents</span></a></h2><ul><li>Install Dependency</li><li>Export your model</li><li>Inference with onnx</li><li>Using streaming model</li></ul><h1 id="install-dependency" tabindex="-1"><a class="header-anchor" href="#install-dependency"><span>Install Dependency</span></a></h1><p>To run this demo, you need to install the following packages.</p><ul><li>espnet_onnx</li><li>torch &gt;= 1.11.0 (already installed in Colab)</li><li>espnet</li><li>espnet_model_zoo</li><li>onnx</li></ul><p><code>torch</code>, <code>espnet</code>, <code>espnet_model_zoo</code>, <code>onnx</code> is required to run the exportation demo.</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#F44747;">!</span><span style="color:#D4D4D4;">pip install -U espnet_onnx espnet espnet_model_zoo onnx</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A9955;"># in this demo, we need to update scipy to avoid an error</span></span>
<span class="line"><span style="color:#F44747;">!</span><span style="color:#D4D4D4;">pip install -U scipy</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h1 id="export-your-model" tabindex="-1"><a class="header-anchor" href="#export-your-model"><span>Export your model</span></a></h1><h2 id="export-model-from-espnet-model-zoo" tabindex="-1"><a class="header-anchor" href="#export-model-from-espnet-model-zoo"><span>Export model from espnet_model_zoo</span></a></h2><p>The easiest way to export a model is to use <code>espnet_model_zoo</code>. You can download, unpack, and export the pretrained models with <code>export_from_pretrained</code> method. <code>espnet_onnx</code> will save the onnx models into cache directory, which is <code>\${HOME}/.cache/espnet_onnx</code> in default.</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#6A9955;"># export the model.</span></span>
<span class="line"><span style="color:#C586C0;">from</span><span style="color:#D4D4D4;"> espnet_onnx.export </span><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> ModelExport</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D4D4D4;">tag_name = </span><span style="color:#CE9178;">&#39;kamo-naoyuki/timit_asr_train_asr_raw_word_valid.acc.ave&#39;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D4D4D4;">m = ModelExport()</span></span>
<span class="line"><span style="color:#D4D4D4;">m.export_from_pretrained(tag_name)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="export-from-custom-model" tabindex="-1"><a class="header-anchor" href="#export-from-custom-model"><span>Export from custom model</span></a></h2><p><code>espnet_onnx</code> can also export your own trained model with <code>export</code> method.</p><p>The following script shows how to export from <code>espnet2.bin.asr_inference.Speech2Text</code> instance. You can also export from a zipped file, by using the <code>export_from_zip</code> function.<br> For this demonstration, I&#39;m using the <code>from_pretrained</code> method to load parameters, but you can load your own model.</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#6A9955;"># prepare the espnet2.bin.asr_inference.Speech2Text instance.</span></span>
<span class="line"><span style="color:#C586C0;">from</span><span style="color:#D4D4D4;"> espnet2.bin.asr_inference </span><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> Speech2Text</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D4D4D4;">tag_name = </span><span style="color:#CE9178;">&#39;kamo-naoyuki/timit_asr_train_asr_raw_word_valid.acc.ave&#39;</span></span>
<span class="line"><span style="color:#D4D4D4;">speech2text = Speech2Text.from_pretrained(tag_name)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#6A9955;"># export model</span></span>
<span class="line"><span style="color:#C586C0;">from</span><span style="color:#D4D4D4;"> espnet_onnx.export </span><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> ModelExport</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D4D4D4;">sample_model_tag = </span><span style="color:#CE9178;">&#39;demo/sample_model_1&#39;</span></span>
<span class="line"><span style="color:#D4D4D4;">m = ModelExport()</span></span>
<span class="line"><span style="color:#D4D4D4;">m.export(</span></span>
<span class="line"><span style="color:#D4D4D4;">    speech2text,</span></span>
<span class="line"><span style="color:#D4D4D4;">    sample_model_tag,</span></span>
<span class="line"><span style="color:#9CDCFE;">    quantize</span><span style="color:#D4D4D4;">=</span><span style="color:#569CD6;">False</span></span>
<span class="line"><span style="color:#D4D4D4;">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h1 id="inference-with-onnx" tabindex="-1"><a class="header-anchor" href="#inference-with-onnx"><span>Inference with onnx</span></a></h1><p>Now, let&#39;s use the exported models for inference.</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#6A9955;"># please provide the tag_name to specify exported model.</span></span>
<span class="line"><span style="color:#D4D4D4;">tag_name = </span><span style="color:#CE9178;">&#39;kamo-naoyuki/timit_asr_train_asr_raw_word_valid.acc.ave&#39;</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#6A9955;"># upload wav file and let&#39;s inference!</span></span>
<span class="line"><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> librosa</span></span>
<span class="line"><span style="color:#C586C0;">from</span><span style="color:#D4D4D4;"> google.colab </span><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> files</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D4D4D4;">wav_file = files.upload()</span></span>
<span class="line"><span style="color:#D4D4D4;">y, sr = librosa.load(</span><span style="color:#4EC9B0;">list</span><span style="color:#D4D4D4;">(wav_file.keys())[</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">], </span><span style="color:#9CDCFE;">sr</span><span style="color:#D4D4D4;">=</span><span style="color:#B5CEA8;">16000</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#6A9955;"># Use the exported onnx file to inference.</span></span>
<span class="line"><span style="color:#C586C0;">from</span><span style="color:#D4D4D4;"> espnet_onnx </span><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> Speech2Text</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D4D4D4;">speech2text = Speech2Text(tag_name)</span></span>
<span class="line"><span style="color:#D4D4D4;">nbest = speech2text(y)</span></span>
<span class="line"><span style="color:#DCDCAA;">print</span><span style="color:#D4D4D4;">(nbest[</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">][</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">])</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h1 id="using-streaming-model" tabindex="-1"><a class="header-anchor" href="#using-streaming-model"><span>Using streaming model</span></a></h1><p>Model exportation is exactly the same as non-streaming model. You can follow the <code>#Export your model</code> chapter.</p><p>As for streaming, you can specify the following configuration additionaly. Usually, these values should be the same as the training configuration.</p><ul><li>block_size</li><li>hop_size</li><li>look_ahead</li></ul><p>The length of the speech should be the same as <code>streaming_model.hop_size</code>. This value is calculated as follows</p><p>$$ \\begin{align} h &amp;= \\text{hop_size} * \\text{encoder.subsample} * \\text{stft.hop_length}\\ \\text{padding} &amp;= (\\text{stft.n_fft} // \\text{stft.hop_length}) * \\text{stft.hop_length} \\ \\text{len(wav)} &amp;= h + \\text{padding} \\end{align} $$</p><p>For example, the length of the speech is 8704 with the following configuration.</p><ul><li>block_size = 40</li><li>hop_size = 16</li><li>look_ahead = 16</li><li>encoder.subsample = 4</li><li>stft.n_fft = 512</li><li>stft.hop_length = 128</li></ul><p>Now, let&#39;s demonstrate the streaming inference.</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#6A9955;"># Export the streaming model.</span></span>
<span class="line"><span style="color:#6A9955;"># Note that the following model is very large</span></span>
<span class="line"><span style="color:#C586C0;">from</span><span style="color:#D4D4D4;"> espnet_onnx.export </span><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> ModelExport</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D4D4D4;">tag_name = </span><span style="color:#CE9178;">&#39;D-Keqi/espnet_asr_train_asr_streaming_transformer_raw_en_bpe500_sp_valid.acc.ave&#39;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D4D4D4;">m = ModelExport()</span></span>
<span class="line"><span style="color:#D4D4D4;">m.export_from_pretrained(tag_name)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#6A9955;"># In this tutorial, we will use the recorded wav file to simulate streaming.</span></span>
<span class="line"><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> librosa</span></span>
<span class="line"><span style="color:#C586C0;">from</span><span style="color:#D4D4D4;"> espnet_onnx </span><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> StreamingSpeech2Text</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D4D4D4;">tag_name = </span><span style="color:#CE9178;">&#39;D-Keqi/espnet_asr_train_asr_streaming_transformer_raw_en_bpe500_sp_valid.acc.ave&#39;</span></span>
<span class="line"><span style="color:#D4D4D4;">streaming_model = StreamingSpeech2Text(tag_name)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A9955;"># upload wav file</span></span>
<span class="line"><span style="color:#C586C0;">from</span><span style="color:#D4D4D4;"> google.colab </span><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> files</span></span>
<span class="line"><span style="color:#D4D4D4;">wav_file = files.upload()</span></span>
<span class="line"><span style="color:#D4D4D4;">y, sr = librosa.load(</span><span style="color:#4EC9B0;">list</span><span style="color:#D4D4D4;">(wav_file.keys())[</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">], </span><span style="color:#9CDCFE;">sr</span><span style="color:#D4D4D4;">=</span><span style="color:#B5CEA8;">16000</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D4D4D4;">num_process = </span><span style="color:#DCDCAA;">len</span><span style="color:#D4D4D4;">(y) // streaming_model.hop_size + </span><span style="color:#B5CEA8;">1</span></span>
<span class="line"><span style="color:#DCDCAA;">print</span><span style="color:#D4D4D4;">(</span><span style="color:#569CD6;">f</span><span style="color:#CE9178;">&quot;I will split your audio file into </span><span style="color:#569CD6;">{</span><span style="color:#D4D4D4;">num_process</span><span style="color:#569CD6;">}</span><span style="color:#CE9178;"> blocks.&quot;</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A9955;"># simulate streaming.</span></span>
<span class="line"><span style="color:#D4D4D4;">streaming_model.start()</span></span>
<span class="line"><span style="color:#C586C0;">for</span><span style="color:#D4D4D4;"> i </span><span style="color:#C586C0;">in</span><span style="color:#DCDCAA;"> range</span><span style="color:#D4D4D4;">(num_process):</span></span>
<span class="line"><span style="color:#6A9955;">  # prepare wav file</span></span>
<span class="line"><span style="color:#D4D4D4;">  start = i * streaming_model.hop_size</span></span>
<span class="line"><span style="color:#D4D4D4;">  end = (i + </span><span style="color:#B5CEA8;">1</span><span style="color:#D4D4D4;">) * streaming_model.hop_size</span></span>
<span class="line"><span style="color:#D4D4D4;">  wav_streaming = y[start : end]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A9955;">  # apply padding if len(wav_streaming) &lt; streaming_model.hop_size</span></span>
<span class="line"><span style="color:#D4D4D4;">  wav_streaming = streaming_model.pad(wav_streaming)</span></span>
<span class="line"><span style="color:#D4D4D4;">  </span></span>
<span class="line"><span style="color:#6A9955;">  # compute asr</span></span>
<span class="line"><span style="color:#D4D4D4;">  nbest = streaming_model(wav_streaming)</span></span>
<span class="line"><span style="color:#DCDCAA;">  print</span><span style="color:#D4D4D4;">(</span><span style="color:#569CD6;">f</span><span style="color:#CE9178;">&#39;Result at position </span><span style="color:#569CD6;">{</span><span style="color:#D4D4D4;">i</span><span style="color:#569CD6;">}</span><span style="color:#CE9178;"> : </span><span style="color:#569CD6;">{</span><span style="color:#D4D4D4;">nbest[</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">][</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">]</span><span style="color:#569CD6;">}</span><span style="color:#CE9178;">&#39;</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D4D4D4;">final_nbest = streaming_model.end()</span></span>
<span class="line"><span style="color:#DCDCAA;">print</span><span style="color:#D4D4D4;">(</span><span style="color:#569CD6;">f</span><span style="color:#CE9178;">&#39;Final result : </span><span style="color:#569CD6;">{</span><span style="color:#D4D4D4;">final_nbest[</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">][</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">]</span><span style="color:#569CD6;">}</span><span style="color:#CE9178;">&#39;</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,29);function u(h,_){const e=l("ExternalLinkIcon");return o(),p("div",null,[c,d,D,m,s("p",null,[n("Author: "),s("a",v,[n("Masao Someki"),i(e)])]),y])}const x=a(r,[["render",u],["__file","onnx_conversion_demo.html.vue"]]);export{x as default};
