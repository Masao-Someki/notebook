import{_ as l,r as o,o as p,c as t,a as s,b as a,d as e,e as r}from"./app-FOR18dDf.js";const i={},c=s("h1",{id:"cmu-11492-11692-spring-2023-spoken-language-understanding",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#cmu-11492-11692-spring-2023-spoken-language-understanding"},[s("span",null,"CMU 11492/11692 Spring 2023: Spoken Language Understanding")])],-1),d=s("p",null,"In this demonstration, we will show you the procedure to conduct spoken language understanding in ESPnet.",-1),D=s("p",null,"Main references:",-1),u={href:"https://github.com/espnet/espnet",target:"_blank",rel:"noopener noreferrer"},y={href:"https://espnet.github.io/espnet/",target:"_blank",rel:"noopener noreferrer"},m=r(`<p>Author:</p><ul><li>Siddhant Arora (siddhana@andrew.cmu.edu)</li></ul><h2 id="objectives" tabindex="-1"><a class="header-anchor" href="#objectives"><span>Objectives</span></a></h2><p>After this demonstration, you are expected to understand some latest advancements in spoken language understanding.</p><h2 id="❗important-notes❗" tabindex="-1"><a class="header-anchor" href="#❗important-notes❗"><span>❗Important Notes❗</span></a></h2><ul><li>We are using Colab to show the demo. However, Colab has some constraints on the total GPU runtime. If you use too much GPU time, you may not be able to use GPU for some time.</li><li>There are multiple in-class checkpoints ✅ throughout this tutorial. <strong>Your participation points are based on these tasks.</strong> Please try your best to follow all the steps! If you encounter issues, please notify the TAs as soon as possible so that we can make an adjustment for you.</li><li>Please submit PDF files of your completed notebooks to Gradescope. You can print the notebook using <code>File -&gt; Print</code> in the menu bar.</li></ul><h2 id="espnet-installation" tabindex="-1"><a class="header-anchor" href="#espnet-installation"><span>ESPnet installation</span></a></h2><p>We follow the ESPnet installation as the previous tutorials (takes around 15 minutes).</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#D4D4D4;">! python -m pip install transformers</span></span>
<span class="line"><span style="color:#F44747;">!</span><span style="color:#D4D4D4;">git clone https://github.com/espnet/espnet /espnet</span></span>
<span class="line"><span style="color:#F44747;">!</span><span style="color:#D4D4D4;">pip install /espnet</span></span>
<span class="line"><span style="color:#D4D4D4;">%pip install -q espnet_model_zoo</span></span>
<span class="line"><span style="color:#D4D4D4;">%pip install fairseq@git+https://github.com//pytorch/fairseq.git@f2146bdc7abf293186de9449bfa2272775e39e1d</span><span style="color:#6A9955;">#egg=fairseq</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="spoken-language-understanding" tabindex="-1"><a class="header-anchor" href="#spoken-language-understanding"><span>Spoken Language Understanding</span></a></h2><p>Spoken Language Understanding (SLU) refers to the task of extracting semantic meaning or linguistic structure from spoken utterances. Some examples include recognizing the intent and their associated entities of a user’s command to take appropriate action, or even understanding the emotion behind a particular utterance, and engaging in conversations with a user by modeling the topic of a conversation. SLU is an essential component of many commercial applications like voice assistants, social bots, and intelligent home devices which have to map speech signals to executable commands every day.</p><p>Conventional SLU systems employ a cascaded approach for sequence labeling, where an automatic speech recognition (ASR) system first recognizes the spoken words from the input audio and a natural language understanding (NLU) system then extracts the intent from the predicted text. These cascaded approaches can effectively utilize pretrained ASR and NLU systems. However, they suffer from error propagation as errors in the ASR transcripts can adversely affect downstream SLU performance. Consequently, in this demo, we focus on end-to-end (E2E) SLU systems. E2E SLU systems aim to predict intent directly from speech. These E2E SLU systems can avoid the cascading of errors but cannot directly utilize strong acoustic and semantic representations from pretrained ASR systems and language models.</p><p>In this tutorial, we will show you some latest E2E SLU model architectures (in ESPnet-SLU) in the field of spoken language understanding, including</p><ul><li>E2E SLU (https://arxiv.org/abs/2111.14706)</li><li>Two Pass E2E SLU (https://arxiv.org/abs/2207.06670)</li></ul><h2 id="overview-of-the-espnet-slu" tabindex="-1"><a class="header-anchor" href="#overview-of-the-espnet-slu"><span>Overview of the ESPnet-SLU</span></a></h2><p>As ASR systems are getting better, there is an increasing interest in using the ASR output directly to do downstream Natural Language Processing (NLP) tasks. With the increase in SLU datasets and methodologies proposed, ESPnet-SLU is an open-source SLU toolkit built on an already existing open-source speech processing toolkit ESPnet. ESPnet-SLU standardize the pipelines involved in building an SLU model like data preparation, model training, and its evaluation. Having ESPnet-SLU would help users build systems for real world scenarios where many speech processing steps need to be applied before running the downstream task. ESPnet also provides an easy access to other speech technologies being developed like data augmentation, encoder sub-sampling, and speech-focused encoders like conformers. They also support many pretrained ASR and NLU systems that can be used as feature extractors in a SLU framework.</p><p>We have shown a sample architecure of our E2E SLU Model in the figure below:</p><p><img src="https://drive.google.com/uc?id=1qzWcOV3x5-cj9OHB-iVtCGfY1tQCWk76" alt="picture"></p><h2 id="_1-e2e-slu" tabindex="-1"><a class="header-anchor" href="#_1-e2e-slu"><span>1. E2E SLU</span></a></h2><h3 id="_1-1-download-sample-audio-file" tabindex="-1"><a class="header-anchor" href="#_1-1-download-sample-audio-file"><span>1.1 Download Sample Audio File</span></a></h3><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#F44747;">!</span><span style="color:#D4D4D4;">gdown </span><span style="color:#F44747;">--</span><span style="color:#DCDCAA;">id</span><span style="color:#F44747;"> 18ANT62ittt7Ai2E8bQRlvT0ZVXXsf1eE</span><span style="color:#D4D4D4;"> -O /content/audio_file.wav</span></span>
<span class="line"><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> os</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> soundfile</span></span>
<span class="line"><span style="color:#C586C0;">from</span><span style="color:#D4D4D4;"> IPython.display </span><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> display, Audio</span></span>
<span class="line"><span style="color:#D4D4D4;">mixwav_mc, sr = soundfile.read(</span><span style="color:#CE9178;">&quot;/content/audio_file.wav&quot;</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"><span style="color:#D4D4D4;">display(Audio(mixwav_mc.T, </span><span style="color:#9CDCFE;">rate</span><span style="color:#D4D4D4;">=sr))</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="question1-✅-checkpoint-1-1-points" tabindex="-1"><a class="header-anchor" href="#question1-✅-checkpoint-1-1-points"><span>Question1 (✅ Checkpoint 1 (1 points))</span></a></h3><p>Run inference on given audio using E2E SLU for intent classification</p><h3 id="_1-2-download-and-load-pretrained-e2e-slu-model" tabindex="-1"><a class="header-anchor" href="#_1-2-download-and-load-pretrained-e2e-slu-model"><span>1.2 Download and Load pretrained E2E SLU Model</span></a></h3><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#F44747;">!</span><span style="color:#D4D4D4;">git lfs clone https://huggingface.co/espnet/siddhana_slurp_new_asr_train_asr_conformer_raw_en_word_valid.acc.ave_10best /content/slurp_first_pass_model</span></span>
<span class="line"><span style="color:#C586C0;">from</span><span style="color:#D4D4D4;"> espnet2.bin.asr_inference </span><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> Speech2Text</span></span>
<span class="line"><span style="color:#D4D4D4;">speech2text_slurp = Speech2Text.from_pretrained(</span></span>
<span class="line"><span style="color:#9CDCFE;">    asr_train_config</span><span style="color:#D4D4D4;">=</span><span style="color:#CE9178;">&quot;/content/slurp_first_pass_model/exp/asr_train_asr_conformer_raw_en_word/config.yaml&quot;</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#9CDCFE;">    asr_model_file</span><span style="color:#D4D4D4;">=</span><span style="color:#CE9178;">&quot;/content/slurp_first_pass_model/exp/asr_train_asr_conformer_raw_en_word/valid.acc.ave_10best.pth&quot;</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#9CDCFE;">    nbest</span><span style="color:#D4D4D4;">=</span><span style="color:#B5CEA8;">1</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#D4D4D4;">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#D4D4D4;">nbests_orig = speech2text_slurp(mixwav_mc)</span></span>
<span class="line"><span style="color:#D4D4D4;">text, *_ = nbests_orig[</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">]</span></span>
<span class="line"><span style="color:#569CD6;">def</span><span style="color:#DCDCAA;"> text_normalizer</span><span style="color:#D4D4D4;">(</span><span style="color:#9CDCFE;">sub_word_transcript</span><span style="color:#D4D4D4;">):</span></span>
<span class="line"><span style="color:#D4D4D4;">    transcript = sub_word_transcript[</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">].replace(</span><span style="color:#CE9178;">&quot;▁&quot;</span><span style="color:#D4D4D4;">, </span><span style="color:#CE9178;">&quot;&quot;</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"><span style="color:#C586C0;">    for</span><span style="color:#D4D4D4;"> sub_word </span><span style="color:#C586C0;">in</span><span style="color:#D4D4D4;"> sub_word_transcript[</span><span style="color:#B5CEA8;">1</span><span style="color:#D4D4D4;">:]:</span></span>
<span class="line"><span style="color:#C586C0;">        if</span><span style="color:#CE9178;"> &quot;▁&quot;</span><span style="color:#569CD6;"> in</span><span style="color:#D4D4D4;"> sub_word:</span></span>
<span class="line"><span style="color:#D4D4D4;">            transcript = transcript + </span><span style="color:#CE9178;">&quot; &quot;</span><span style="color:#D4D4D4;"> + sub_word.replace(</span><span style="color:#CE9178;">&quot;▁&quot;</span><span style="color:#D4D4D4;">, </span><span style="color:#CE9178;">&quot;&quot;</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"><span style="color:#C586C0;">        else</span><span style="color:#D4D4D4;">:</span></span>
<span class="line"><span style="color:#D4D4D4;">            transcript = transcript + sub_word</span></span>
<span class="line"><span style="color:#C586C0;">    return</span><span style="color:#D4D4D4;"> transcript</span></span>
<span class="line"><span style="color:#D4D4D4;">intent_text=</span><span style="color:#CE9178;">&quot;{scenario: &quot;</span><span style="color:#D4D4D4;">+text.split()[</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">].split(</span><span style="color:#CE9178;">&quot;_&quot;</span><span style="color:#D4D4D4;">)[</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">]+</span><span style="color:#CE9178;">&quot;, action: &quot;</span><span style="color:#D4D4D4;">+</span><span style="color:#CE9178;">&quot;_&quot;</span><span style="color:#D4D4D4;">.join(text.split()[</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">].split(</span><span style="color:#CE9178;">&quot;_&quot;</span><span style="color:#D4D4D4;">)[</span><span style="color:#B5CEA8;">1</span><span style="color:#D4D4D4;">:])+</span><span style="color:#CE9178;">&quot;}&quot;</span></span>
<span class="line"><span style="color:#DCDCAA;">print</span><span style="color:#D4D4D4;">(</span><span style="color:#569CD6;">f</span><span style="color:#CE9178;">&quot;INTENT: </span><span style="color:#569CD6;">{</span><span style="color:#D4D4D4;">intent_text</span><span style="color:#569CD6;">}</span><span style="color:#CE9178;">&quot;</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"><span style="color:#D4D4D4;">transcript=text_normalizer(text.split()[</span><span style="color:#B5CEA8;">1</span><span style="color:#D4D4D4;">:])</span></span>
<span class="line"><span style="color:#DCDCAA;">print</span><span style="color:#D4D4D4;">(</span><span style="color:#569CD6;">f</span><span style="color:#CE9178;">&quot;ASR hypothesis: </span><span style="color:#569CD6;">{</span><span style="color:#D4D4D4;">transcript</span><span style="color:#569CD6;">}</span><span style="color:#CE9178;">&quot;</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"><span style="color:#DCDCAA;">print</span><span style="color:#D4D4D4;">(</span><span style="color:#569CD6;">f</span><span style="color:#CE9178;">&quot;E2E SLU model fails to predict the correct action.&quot;</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_2-two-pass-e2e-slu" tabindex="-1"><a class="header-anchor" href="#_2-two-pass-e2e-slu"><span>2. Two Pass E2E SLU</span></a></h2><p>However, recent work has shown that E2E-SLU systems struggle to generalize to unique phrasing for the same intent, suggesting an opportunity for enhancing semantic modeling of existing SLU systems. A number of approaches have been proposed to learn semantic content directly from audio. These approaches aim to incorporate pretrained language models to improve semantic processing of SLU architectures. In this demo, we use the Two Pass E2E SLU model where the second pass model improves on the initial prediction by combining acoustic information from the entire speech and semantic information from ASR-hypothesis using a deliberation network.</p><p><img src="https://drive.google.com/uc?id=1imEA98mIqcC6i-Cgdc84msHKliaVgtdf" alt="pitcture"></p><h3 id="question2-✅-checkpoint-2-1-points" tabindex="-1"><a class="header-anchor" href="#question2-✅-checkpoint-2-1-points"><span>Question2 (✅ Checkpoint 2 (1 points))</span></a></h3><p>Run inference on given audio using 2 pass SLU</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#F44747;">!</span><span style="color:#D4D4D4;">git lfs clone https://huggingface.co/espnet/slurp_slu_2pass /content/slurp_second_pass_model</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#C586C0;">from</span><span style="color:#D4D4D4;"> espnet2.bin.slu_inference </span><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> Speech2Understand</span></span>
<span class="line"><span style="color:#C586C0;">from</span><span style="color:#D4D4D4;"> transformers </span><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> AutoModel, AutoTokenizer</span></span>
<span class="line"><span style="color:#D4D4D4;">speech2text_second_pass_slurp = Speech2Understand.from_pretrained(</span></span>
<span class="line"><span style="color:#9CDCFE;">    slu_train_config</span><span style="color:#D4D4D4;">=</span><span style="color:#CE9178;">&quot;/content/slurp_second_pass_model/exp/slu_train_asr_bert_conformer_deliberation_raw_en_word/config.yaml&quot;</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#9CDCFE;">    slu_model_file</span><span style="color:#D4D4D4;">=</span><span style="color:#CE9178;">&quot;/content/slurp_second_pass_model/exp/slu_train_asr_bert_conformer_deliberation_raw_en_word/valid.acc.ave_10best.pth&quot;</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#9CDCFE;">    nbest</span><span style="color:#D4D4D4;">=</span><span style="color:#B5CEA8;">1</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#D4D4D4;">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#C586C0;">from</span><span style="color:#D4D4D4;"> espnet2.tasks.slu </span><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> SLUTask</span></span>
<span class="line"><span style="color:#D4D4D4;">preprocess_fn=SLUTask.build_preprocess_fn(</span></span>
<span class="line"><span style="color:#D4D4D4;">            speech2text_second_pass_slurp.asr_train_args, </span><span style="color:#569CD6;">False</span></span>
<span class="line"><span style="color:#D4D4D4;">        )</span></span>
<span class="line"><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> numpy </span><span style="color:#C586C0;">as</span><span style="color:#D4D4D4;"> np</span></span>
<span class="line"><span style="color:#D4D4D4;">transcript = preprocess_fn.text_cleaner(transcript)</span></span>
<span class="line"><span style="color:#D4D4D4;">tokens = preprocess_fn.transcript_tokenizer.text2tokens(transcript)</span></span>
<span class="line"><span style="color:#D4D4D4;">text_ints = np.array(preprocess_fn.transcript_token_id_converter.tokens2ids(tokens), </span><span style="color:#9CDCFE;">dtype</span><span style="color:#D4D4D4;">=np.int64)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> torch</span></span>
<span class="line"><span style="color:#D4D4D4;">nbests = speech2text_second_pass_slurp(mixwav_mc,torch.tensor(text_ints))</span></span>
<span class="line"><span style="color:#D4D4D4;">text1, *_ = nbests[</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">]</span></span>
<span class="line"><span style="color:#D4D4D4;">intent_text=</span><span style="color:#CE9178;">&quot;{scenario: &quot;</span><span style="color:#D4D4D4;">+text1.split()[</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">].split(</span><span style="color:#CE9178;">&quot;_&quot;</span><span style="color:#D4D4D4;">)[</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">]+</span><span style="color:#CE9178;">&quot;, action: &quot;</span><span style="color:#D4D4D4;">+</span><span style="color:#CE9178;">&quot;_&quot;</span><span style="color:#D4D4D4;">.join(text1.split()[</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">].split(</span><span style="color:#CE9178;">&quot;_&quot;</span><span style="color:#D4D4D4;">)[</span><span style="color:#B5CEA8;">1</span><span style="color:#D4D4D4;">:])+</span><span style="color:#CE9178;">&quot;}&quot;</span></span>
<span class="line"><span style="color:#DCDCAA;">print</span><span style="color:#D4D4D4;">(</span><span style="color:#569CD6;">f</span><span style="color:#CE9178;">&quot;INTENT: </span><span style="color:#569CD6;">{</span><span style="color:#D4D4D4;">intent_text</span><span style="color:#569CD6;">}</span><span style="color:#CE9178;">&quot;</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"><span style="color:#D4D4D4;">transcript=text_normalizer(text1.split()[</span><span style="color:#B5CEA8;">1</span><span style="color:#D4D4D4;">:])</span></span>
<span class="line"><span style="color:#DCDCAA;">print</span><span style="color:#D4D4D4;">(</span><span style="color:#569CD6;">f</span><span style="color:#CE9178;">&quot;ASR hypothesis: </span><span style="color:#569CD6;">{</span><span style="color:#D4D4D4;">transcript</span><span style="color:#569CD6;">}</span><span style="color:#CE9178;">&quot;</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"><span style="color:#DCDCAA;">print</span><span style="color:#D4D4D4;">(</span><span style="color:#569CD6;">f</span><span style="color:#CE9178;">&quot;Second pass SLU model successfully recognizes the correct action.&quot;</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_3-e2e-slu-for-slot-filling" tabindex="-1"><a class="header-anchor" href="#_3-e2e-slu-for-slot-filling"><span>3. E2E SLU for Slot Filling</span></a></h2><h3 id="question3-✅-checkpoint-3-1-point" tabindex="-1"><a class="header-anchor" href="#question3-✅-checkpoint-3-1-point"><span>Question3 (✅ Checkpoint 3 (1 point))</span></a></h3><p>Run inference on given audio using E2E SLU for slot filling</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#F44747;">!</span><span style="color:#D4D4D4;">gdown </span><span style="color:#F44747;">--</span><span style="color:#DCDCAA;">id</span><span style="color:#F44747;"> 1ezs8IPutLr</span><span style="color:#D4D4D4;">-C0PXKb6pfOlb6XXFDXcPd -O /content/audio_slurp_entity_file.wav</span></span>
<span class="line"><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> os</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> soundfile</span></span>
<span class="line"><span style="color:#C586C0;">from</span><span style="color:#D4D4D4;"> IPython.display </span><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> display, Audio</span></span>
<span class="line"><span style="color:#D4D4D4;">mixwav_mc, sr = soundfile.read(</span><span style="color:#CE9178;">&quot;/content/audio_slurp_entity_file.wav&quot;</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"><span style="color:#D4D4D4;">display(Audio(mixwav_mc.T, </span><span style="color:#9CDCFE;">rate</span><span style="color:#D4D4D4;">=sr))</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#F44747;">!</span><span style="color:#D4D4D4;">git lfs clone https://huggingface.co/espnet/siddhana_slurp_entity_asr_train_asr_conformer_raw_en_word_valid.acc.ave_10best /content/slurp_entity_model</span></span>
<span class="line"><span style="color:#C586C0;">from</span><span style="color:#D4D4D4;"> espnet2.bin.asr_inference </span><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> Speech2Text</span></span>
<span class="line"><span style="color:#D4D4D4;">speech2text_slurp = Speech2Text.from_pretrained(</span></span>
<span class="line"><span style="color:#9CDCFE;">    asr_train_config</span><span style="color:#D4D4D4;">=</span><span style="color:#CE9178;">&quot;/content/slurp_entity_model/exp/asr_train_asr_conformer_raw_en_word/config.yaml&quot;</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#9CDCFE;">    asr_model_file</span><span style="color:#D4D4D4;">=</span><span style="color:#CE9178;">&quot;/content/slurp_entity_model/exp/asr_train_asr_conformer_raw_en_word/valid.acc.ave_10best.pth&quot;</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#9CDCFE;">    nbest</span><span style="color:#D4D4D4;">=</span><span style="color:#B5CEA8;">1</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#D4D4D4;">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#D4D4D4;">nbests_orig = speech2text_slurp(mixwav_mc)</span></span>
<span class="line"><span style="color:#D4D4D4;">text, *_ = nbests_orig[</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">]</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#569CD6;">def</span><span style="color:#DCDCAA;"> entity_text_normalizer</span><span style="color:#D4D4D4;">(</span><span style="color:#9CDCFE;">sub_word_transcript_list</span><span style="color:#D4D4D4;">):</span></span>
<span class="line"><span style="color:#D4D4D4;">    transcript_dict={}</span></span>
<span class="line"><span style="color:#C586C0;">    for</span><span style="color:#D4D4D4;"> sub_word_transcript_new </span><span style="color:#C586C0;">in</span><span style="color:#D4D4D4;"> sub_word_transcript_list:</span></span>
<span class="line"><span style="color:#D4D4D4;">      sub_word_transcript=sub_word_transcript_new.split()</span></span>
<span class="line"><span style="color:#6A9955;">      # print(sub_word_transcript_list)</span></span>
<span class="line"><span style="color:#6A9955;">      # print(sub_word_transcript)</span></span>
<span class="line"><span style="color:#D4D4D4;">      transcript = sub_word_transcript[</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">].replace(</span><span style="color:#CE9178;">&quot;▁&quot;</span><span style="color:#D4D4D4;">, </span><span style="color:#CE9178;">&quot;&quot;</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"><span style="color:#C586C0;">      for</span><span style="color:#D4D4D4;"> sub_word </span><span style="color:#C586C0;">in</span><span style="color:#D4D4D4;"> sub_word_transcript[</span><span style="color:#B5CEA8;">1</span><span style="color:#D4D4D4;">:]:</span></span>
<span class="line"><span style="color:#C586C0;">          if</span><span style="color:#CE9178;"> &quot;▁&quot;</span><span style="color:#569CD6;"> in</span><span style="color:#D4D4D4;"> sub_word:</span></span>
<span class="line"><span style="color:#D4D4D4;">              transcript = transcript + </span><span style="color:#CE9178;">&quot; &quot;</span><span style="color:#D4D4D4;"> + sub_word.replace(</span><span style="color:#CE9178;">&quot;▁&quot;</span><span style="color:#D4D4D4;">, </span><span style="color:#CE9178;">&quot;&quot;</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"><span style="color:#C586C0;">          else</span><span style="color:#D4D4D4;">:</span></span>
<span class="line"><span style="color:#D4D4D4;">              transcript = transcript + sub_word</span></span>
<span class="line"><span style="color:#D4D4D4;">      transcript_dict[transcript.split(</span><span style="color:#CE9178;">&quot; FILL &quot;</span><span style="color:#D4D4D4;">)[</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">]]=transcript.split(</span><span style="color:#CE9178;">&quot; FILL &quot;</span><span style="color:#D4D4D4;">)[</span><span style="color:#B5CEA8;">1</span><span style="color:#D4D4D4;">]</span></span>
<span class="line"><span style="color:#C586C0;">    return</span><span style="color:#D4D4D4;"> transcript_dict</span></span>
<span class="line"><span style="color:#D4D4D4;">intent_text=</span><span style="color:#CE9178;">&quot;{scenario: &quot;</span><span style="color:#D4D4D4;">+text.split()[</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">].split(</span><span style="color:#CE9178;">&quot;_&quot;</span><span style="color:#D4D4D4;">)[</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">]+</span><span style="color:#CE9178;">&quot;, action: &quot;</span><span style="color:#D4D4D4;">+</span><span style="color:#CE9178;">&quot;_&quot;</span><span style="color:#D4D4D4;">.join(text.split()[</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">].split(</span><span style="color:#CE9178;">&quot;_&quot;</span><span style="color:#D4D4D4;">)[</span><span style="color:#B5CEA8;">1</span><span style="color:#D4D4D4;">:])+</span><span style="color:#CE9178;">&quot;}&quot;</span></span>
<span class="line"><span style="color:#6A9955;"># print(text)</span></span>
<span class="line"><span style="color:#DCDCAA;">print</span><span style="color:#D4D4D4;">(</span><span style="color:#569CD6;">f</span><span style="color:#CE9178;">&quot;INTENT: </span><span style="color:#569CD6;">{</span><span style="color:#D4D4D4;">intent_text</span><span style="color:#569CD6;">}</span><span style="color:#CE9178;">&quot;</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"><span style="color:#6A9955;"># print(&quot; &quot;.join(text.split()[1:]).split(&quot;▁SEP&quot;)[-1].split())</span></span>
<span class="line"><span style="color:#D4D4D4;">transcript=text_normalizer(</span><span style="color:#CE9178;">&quot; &quot;</span><span style="color:#D4D4D4;">.join(text.split()[</span><span style="color:#B5CEA8;">1</span><span style="color:#D4D4D4;">:]).split(</span><span style="color:#CE9178;">&quot;▁SEP&quot;</span><span style="color:#D4D4D4;">)[-</span><span style="color:#B5CEA8;">1</span><span style="color:#D4D4D4;">].split())</span></span>
<span class="line"><span style="color:#DCDCAA;">print</span><span style="color:#D4D4D4;">(</span><span style="color:#569CD6;">f</span><span style="color:#CE9178;">&quot;ASR hypothesis: </span><span style="color:#569CD6;">{</span><span style="color:#D4D4D4;">transcript</span><span style="color:#569CD6;">}</span><span style="color:#CE9178;">&quot;</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"><span style="color:#D4D4D4;">entity_transcript=entity_text_normalizer(</span><span style="color:#CE9178;">&quot; &quot;</span><span style="color:#D4D4D4;">.join(text.split()[</span><span style="color:#B5CEA8;">1</span><span style="color:#D4D4D4;">:]).split(</span><span style="color:#CE9178;">&quot;▁SEP&quot;</span><span style="color:#D4D4D4;">)[</span><span style="color:#B5CEA8;">1</span><span style="color:#D4D4D4;">:-</span><span style="color:#B5CEA8;">1</span><span style="color:#D4D4D4;">])</span></span>
<span class="line"><span style="color:#DCDCAA;">print</span><span style="color:#D4D4D4;">(</span><span style="color:#569CD6;">f</span><span style="color:#CE9178;">&quot;Slot dictionary: </span><span style="color:#569CD6;">{</span><span style="color:#D4D4D4;">entity_transcript</span><span style="color:#569CD6;">}</span><span style="color:#CE9178;">&quot;</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_4-e2e-slu-for-sentiment-analysis" tabindex="-1"><a class="header-anchor" href="#_4-e2e-slu-for-sentiment-analysis"><span>4. E2E SLU for Sentiment Analysis</span></a></h2><h3 id="question4-✅-checkpoint-4-1-point" tabindex="-1"><a class="header-anchor" href="#question4-✅-checkpoint-4-1-point"><span>Question4 (✅ Checkpoint 4 (1 point))</span></a></h3><p>Run inference on given audio using E2E SLU for sentiment analysis</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#F44747;">!</span><span style="color:#D4D4D4;">gdown </span><span style="color:#F44747;">--</span><span style="color:#DCDCAA;">id</span><span style="color:#F44747;"> 1CZzmpMliwSzja9TdBV7wmidlGepZBEUi</span><span style="color:#D4D4D4;"> -O /content/audio_iemocap_file.wav</span></span>
<span class="line"><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> os</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> soundfile</span></span>
<span class="line"><span style="color:#C586C0;">from</span><span style="color:#D4D4D4;"> IPython.display </span><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> display, Audio</span></span>
<span class="line"><span style="color:#D4D4D4;">mixwav_mc, sr = soundfile.read(</span><span style="color:#CE9178;">&quot;/content/audio_iemocap_file.wav&quot;</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"><span style="color:#D4D4D4;">display(Audio(mixwav_mc.T, </span><span style="color:#9CDCFE;">rate</span><span style="color:#D4D4D4;">=sr))</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#F44747;">!</span><span style="color:#D4D4D4;">git lfs clone https://huggingface.co/espnet/YushiUeda_iemocap_sentiment_asr_train_asr_conformer /content/iemocap_model</span></span>
<span class="line"><span style="color:#C586C0;">from</span><span style="color:#D4D4D4;"> espnet2.bin.asr_inference </span><span style="color:#C586C0;">import</span><span style="color:#D4D4D4;"> Speech2Text</span></span>
<span class="line"><span style="color:#D4D4D4;">speech2text_iemocap = Speech2Text.from_pretrained(</span></span>
<span class="line"><span style="color:#9CDCFE;">    asr_train_config</span><span style="color:#D4D4D4;">=</span><span style="color:#CE9178;">&quot;/content/iemocap_model/exp/asr_train_asr_conformer_raw_en_word/config.yaml&quot;</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#9CDCFE;">    asr_model_file</span><span style="color:#D4D4D4;">=</span><span style="color:#CE9178;">&quot;/content/iemocap_model/exp/asr_train_asr_conformer_raw_en_word/valid.acc.ave_10best.pth&quot;</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#9CDCFE;">    nbest</span><span style="color:#D4D4D4;">=</span><span style="color:#B5CEA8;">1</span><span style="color:#D4D4D4;">,</span></span>
<span class="line"><span style="color:#D4D4D4;">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span style="color:#D4D4D4;">nbests_orig = speech2text_iemocap(mixwav_mc)</span></span>
<span class="line"><span style="color:#D4D4D4;">text, *_ = nbests_orig[</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">]</span></span>
<span class="line"><span style="color:#D4D4D4;">sentiment_text=text.split()[</span><span style="color:#B5CEA8;">0</span><span style="color:#D4D4D4;">]</span></span>
<span class="line"><span style="color:#DCDCAA;">print</span><span style="color:#D4D4D4;">(</span><span style="color:#569CD6;">f</span><span style="color:#CE9178;">&quot;SENTIMENT: </span><span style="color:#569CD6;">{</span><span style="color:#D4D4D4;">sentiment_text</span><span style="color:#569CD6;">}</span><span style="color:#CE9178;">&quot;</span><span style="color:#D4D4D4;">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="question5-✅-checkpoint-5-1-point" tabindex="-1"><a class="header-anchor" href="#question5-✅-checkpoint-5-1-point"><span>Question5 (✅ Checkpoint 5 (1 point))</span></a></h3><p>Discuss about potential advantages of integrating pre-trained LMs inside E2E SLU framework compared to using them in cascaded manner?</p><p>[ANSWER HERE]</p>`,51);function v(_,h){const n=o("ExternalLinkIcon");return p(),t("div",null,[c,d,D,s("ul",null,[s("li",null,[s("a",u,[a("ESPnet repository"),e(n)])]),s("li",null,[s("a",y,[a("ESPnet documentation"),e(n)])])]),m])}const b=l(i,[["render",v],["__file","SpokenLanguageUnderstanding_CMU_11492_692_Spring2023(Assignment6).html.vue"]]);export{b as default};
