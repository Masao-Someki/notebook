<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.2" />
    <style>
      :root {
        --c-bg: #fff;
      }
      html.dark {
        --c-bg: #22272e;
      }
      html,
      body {
        background-color: var(--c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem('vuepress-color-scheme')
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia('(prefers-color-scheme: dark)').matches
      if (userMode === 'dark' || (userMode !== 'light' && systemDarkMode)) {
        document.documentElement.classList.toggle('dark', true)
      }
    </script>
    <link rel="manifest" href="/manifest.webmanifest"><meta name="application-name" content="Example"><meta name="apple-mobile-web-app-title" content="Example"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="msapplication-TileColor" content="#3eaf7c"><meta name="theme-color" content="#3eaf7c"><title>Text-to-Speech (Recipe) | ESPnet-Example</title><meta name="description" content="Example notebooks for ESPnet">
    <link rel="preload" href="/notebook/assets/style-cp41dQ25.css" as="style"><link rel="stylesheet" href="/notebook/assets/style-cp41dQ25.css">
    <link rel="modulepreload" href="/notebook/assets/app-FOR18dDf.js"><link rel="modulepreload" href="/notebook/assets/tts_cli.html-Elg6sapX.js"><link rel="modulepreload" href="/notebook/assets/tts_cli.html-OLkBd5Fu.js">
    <link rel="prefetch" href="/notebook/assets/index.html-XAvCBsD6.js" as="script"><link rel="prefetch" href="/notebook/assets/DataPreparation_CMU_11492_692_Spring2023(Assignment0).html-KBtpWdkS.js" as="script"><link rel="prefetch" href="/notebook/assets/SpeechEnhancement_CMU_11492_692_Spring2023(Assignment7).html-ojQTonzi.js" as="script"><link rel="prefetch" href="/notebook/assets/SpokenLanguageUnderstanding_CMU_11492_692_Spring2023(Assignment6).html-k7t3PiyY.js" as="script"><link rel="prefetch" href="/notebook/assets/TextToSpeech_CMU_11492_692_Spring2023(Assignment8).html-mugYinQi.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html-xjN-GwTF.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html-IaNcm8K-.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_tutorial_2021_CMU_11751_18781.html-IMfnLI01.js" as="script"><link rel="prefetch" href="/notebook/assets/asr_cli.html-JH3saHIF.js" as="script"><link rel="prefetch" href="/notebook/assets/asr_library.html-nD4wSonE.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_asr_realtime_demo.html-31qj-nF8.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_asr_transfer_learning_demo.html-K8AGvfnJ.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_streaming_asr_demo.html-NgcmLWnC.js" as="script"><link rel="prefetch" href="/notebook/assets/onnx_conversion_demo.html-wfKipc9w.js" as="script"><link rel="prefetch" href="/notebook/assets/pretrained.html--Y7vPVCq.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet_se_demonstration_for_waspaa_2021.html-_RqduImg.js" as="script"><link rel="prefetch" href="/notebook/assets/se_demo.html-zhHwqNB_.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_2pass_slu_demo.html-SOe7ZUtq.js" as="script"><link rel="prefetch" href="/notebook/assets/st_demo.html-_JBPLyfl.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_tts_realtime_demo.html-9h1FXENI.js" as="script"><link rel="prefetch" href="/notebook/assets/tts_realtime_demo.html-Bgn0MtVH.js" as="script"><link rel="prefetch" href="/notebook/assets/finetune_owsm.html-oRbSv_3K.js" as="script"><link rel="prefetch" href="/notebook/assets/finetune_with_lora.html-53DWrWT9.js" as="script"><link rel="prefetch" href="/notebook/assets/train.html-ZtrUU739.js" as="script"><link rel="prefetch" href="/notebook/assets/tacotron2.html-lMDTfHXx.js" as="script"><link rel="prefetch" href="/notebook/assets/404.html-6Yl8cQE3.js" as="script"><link rel="prefetch" href="/notebook/assets/index.html-Fa1mvKNA.js" as="script"><link rel="prefetch" href="/notebook/assets/DataPreparation_CMU_11492_692_Spring2023(Assignment0).html-yZnfE8Rl.js" as="script"><link rel="prefetch" href="/notebook/assets/SpeechEnhancement_CMU_11492_692_Spring2023(Assignment7).html-EtOqTzx1.js" as="script"><link rel="prefetch" href="/notebook/assets/SpokenLanguageUnderstanding_CMU_11492_692_Spring2023(Assignment6).html-3QqySz0B.js" as="script"><link rel="prefetch" href="/notebook/assets/TextToSpeech_CMU_11492_692_Spring2023(Assignment8).html-oKNm4LpP.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html-4zeeKKut.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html-Xne2M8JW.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_tutorial_2021_CMU_11751_18781.html-HhdidVDJ.js" as="script"><link rel="prefetch" href="/notebook/assets/asr_cli.html-knKjgurg.js" as="script"><link rel="prefetch" href="/notebook/assets/asr_library.html-Kz7KwH4E.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_asr_realtime_demo.html-RYvF9e8R.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_asr_transfer_learning_demo.html-IksoduPb.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_streaming_asr_demo.html-6EF7rYtq.js" as="script"><link rel="prefetch" href="/notebook/assets/onnx_conversion_demo.html-1dXBgI7d.js" as="script"><link rel="prefetch" href="/notebook/assets/pretrained.html-bRY7ZLad.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet_se_demonstration_for_waspaa_2021.html-53aPYjLT.js" as="script"><link rel="prefetch" href="/notebook/assets/se_demo.html-0y7hJZOb.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_2pass_slu_demo.html-LPf_aa6M.js" as="script"><link rel="prefetch" href="/notebook/assets/st_demo.html-GjLoLXxU.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_tts_realtime_demo.html-NCcWLTBY.js" as="script"><link rel="prefetch" href="/notebook/assets/tts_realtime_demo.html-wTutqUQW.js" as="script"><link rel="prefetch" href="/notebook/assets/finetune_owsm.html-BKHMtCfm.js" as="script"><link rel="prefetch" href="/notebook/assets/finetune_with_lora.html-h3VNWfNm.js" as="script"><link rel="prefetch" href="/notebook/assets/train.html-zSf_6N6D.js" as="script"><link rel="prefetch" href="/notebook/assets/tacotron2.html-gzrp5q7X.js" as="script"><link rel="prefetch" href="/notebook/assets/404.html-8hkKDKOa.js" as="script"><link rel="prefetch" href="/notebook/assets/NpmBadge-ZlH3swud.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="theme-container"><!--[--><header class="navbar"><div class="toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a href="/notebook/" class=""><img class="logo" src="/notebook/images/espnet_logo1.png" alt="ESPnet-Example"><span class="site-name can-hide" aria-hidden="true">ESPnet-Example</span></a></span><div class="navbar-items-wrapper" style=""><!--[--><!--]--><nav class="navbar-items can-hide" aria-label="site navigation"><!--[--><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="ESPnet2"><span class="title">ESPnet2</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="ESPnet2"><span class="title">ESPnet2</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>ASR</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/asr/asr_cli.html" class="" aria-label="Speech Recognition (Recipe)"><!--[--><!--]--> Speech Recognition (Recipe) <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/asr/asr_library.html" class="" aria-label="Speech Recognition (Library)"><!--[--><!--]--> Speech Recognition (Library) <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/asr/espnet2_asr_realtime_demo.html" class="" aria-label="ESPnet2-ASR realtime demonstration"><!--[--><!--]--> ESPnet2-ASR realtime demonstration <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/asr/espnet2_asr_transfer_learning_demo.html" class="" aria-label="Use transfer learning for ASR in ESPnet2"><!--[--><!--]--> Use transfer learning for ASR in ESPnet2 <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/asr/espnet2_streaming_asr_demo.html" class="" aria-label="ESPnet2 real streaming Transformer demonstration"><!--[--><!--]--> ESPnet2 real streaming Transformer demonstration <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>TTS</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/tts/espnet2_tts_realtime_demo.html" class="" aria-label="ESPnet2-TTS realtime demonstration"><!--[--><!--]--> ESPnet2-TTS realtime demonstration <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a aria-current="page" href="/notebook/espnet2/tts/tts_cli.html" class="router-link-active router-link-exact-active router-link-active" aria-label="Text-to-Speech (Recipe)"><!--[--><!--]--> Text-to-Speech (Recipe) <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/tts/tts_realtime_demo.html" class="" aria-label="ESPnet real time E2E-TTS demonstration"><!--[--><!--]--> ESPnet real time E2E-TTS demonstration <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>SE</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/se/se_demo.html" class="" aria-label="ESPnet Speech Enhancement Demonstration"><!--[--><!--]--> ESPnet Speech Enhancement Demonstration <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/se/espnet_se_demonstration_for_waspaa_2021.html" class="" aria-label="ESPnet Speech Enhancement Demonstration"><!--[--><!--]--> ESPnet Speech Enhancement Demonstration <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>SLU</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/slu/espnet2_2pass_slu_demo.html" class="" aria-label="ESPNET 2 pass SLU Demonstration"><!--[--><!--]--> ESPNET 2 pass SLU Demonstration <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>ST</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/st/st_demo.html" class="" aria-label="ESPnet Speech Translation Demonstration"><!--[--><!--]--> ESPnet Speech Translation Demonstration <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>Others</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/others/pretrained.html" class="" aria-label="Pretrained Model"><!--[--><!--]--> Pretrained Model <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/others/onnx_conversion_demo.html" class="" aria-label="espnet_onnx demonstration"><!--[--><!--]--> espnet_onnx demonstration <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><!--]--></ul></div></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="Tutorials"><span class="title">Tutorials</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="Tutorials"><span class="title">Tutorials</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a href="/notebook/tutorials/DataPreparation_CMU_11492_692_Spring2023(Assignment0).html" class="" aria-label="CMU 11492/11692 Spring 2023: Data preparation"><!--[--><!--]--> CMU 11492/11692 Spring 2023: Data preparation <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/notebook/tutorials/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html" class="" aria-label="CMU 11751/18781 Fall 2022: ESPnet Tutorial2 (New task)"><!--[--><!--]--> CMU 11751/18781 Fall 2022: ESPnet Tutorial2 (New task) <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/notebook/tutorials/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html" class="" aria-label="CMU 11751/18781 Fall 2022: ESPnet Tutorial"><!--[--><!--]--> CMU 11751/18781 Fall 2022: ESPnet Tutorial <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/notebook/tutorials/espnet2_tutorial_2021_CMU_11751_18781.html" class="" aria-label="CMU 11751/18781 2021: ESPnet Tutorial"><!--[--><!--]--> CMU 11751/18781 2021: ESPnet Tutorial <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/notebook/tutorials/SpeechEnhancement_CMU_11492_692_Spring2023(Assignment7).html" class="" aria-label="CMU 11492/11692 Spring 2023: Speech Enhancement"><!--[--><!--]--> CMU 11492/11692 Spring 2023: Speech Enhancement <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/notebook/tutorials/SpokenLanguageUnderstanding_CMU_11492_692_Spring2023(Assignment6).html" class="" aria-label="CMU 11492/11692 Spring 2023: Spoken Language Understanding"><!--[--><!--]--> CMU 11492/11692 Spring 2023: Spoken Language Understanding <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/notebook/tutorials/TextToSpeech_CMU_11492_692_Spring2023(Assignment8).html" class="" aria-label="CMU 11492/11692 Spring 2023: Text to Speech"><!--[--><!--]--> CMU 11492/11692 Spring 2023: Text to Speech <!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="ESPnetEasy"><span class="title">ESPnetEasy</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="ESPnetEasy"><span class="title">ESPnetEasy</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>ASR</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnetez/asr/train.html" class="" aria-label="Sample demo for ESPnet-Easy!"><!--[--><!--]--> Sample demo for ESPnet-Easy! <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnetez/asr/finetune_with_lora.html" class="" aria-label="Finetune Model with ESPnet-Easy"><!--[--><!--]--> Finetune Model with ESPnet-Easy <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnetez/asr/finetune_owsm.html" class="" aria-label="OWSM finetuning with custom dataset"><!--[--><!--]--> OWSM finetuning with custom dataset <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>TTS</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnetez/tts/tacotron2.html" class="" aria-label="TTS demo for ESPnet-Easy!"><!--[--><!--]--> TTS demo for ESPnet-Easy! <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><!--]--></ul></div></div><!--]--></nav><!--[--><!--]--><button class="toggle-color-mode-button" title="toggle color mode"><svg style="" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg style="display:none;" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><form class="search-box" role="search"><input type="search" placeholder="Search" autocomplete="off" spellcheck="false" value><!----></form></div></header><!--]--><div class="sidebar-mask"></div><!--[--><aside class="sidebar"><nav class="navbar-items" aria-label="site navigation"><!--[--><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="ESPnet2"><span class="title">ESPnet2</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="ESPnet2"><span class="title">ESPnet2</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>ASR</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/asr/asr_cli.html" class="" aria-label="Speech Recognition (Recipe)"><!--[--><!--]--> Speech Recognition (Recipe) <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/asr/asr_library.html" class="" aria-label="Speech Recognition (Library)"><!--[--><!--]--> Speech Recognition (Library) <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/asr/espnet2_asr_realtime_demo.html" class="" aria-label="ESPnet2-ASR realtime demonstration"><!--[--><!--]--> ESPnet2-ASR realtime demonstration <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/asr/espnet2_asr_transfer_learning_demo.html" class="" aria-label="Use transfer learning for ASR in ESPnet2"><!--[--><!--]--> Use transfer learning for ASR in ESPnet2 <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/asr/espnet2_streaming_asr_demo.html" class="" aria-label="ESPnet2 real streaming Transformer demonstration"><!--[--><!--]--> ESPnet2 real streaming Transformer demonstration <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>TTS</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/tts/espnet2_tts_realtime_demo.html" class="" aria-label="ESPnet2-TTS realtime demonstration"><!--[--><!--]--> ESPnet2-TTS realtime demonstration <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a aria-current="page" href="/notebook/espnet2/tts/tts_cli.html" class="router-link-active router-link-exact-active router-link-active" aria-label="Text-to-Speech (Recipe)"><!--[--><!--]--> Text-to-Speech (Recipe) <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/tts/tts_realtime_demo.html" class="" aria-label="ESPnet real time E2E-TTS demonstration"><!--[--><!--]--> ESPnet real time E2E-TTS demonstration <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>SE</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/se/se_demo.html" class="" aria-label="ESPnet Speech Enhancement Demonstration"><!--[--><!--]--> ESPnet Speech Enhancement Demonstration <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/se/espnet_se_demonstration_for_waspaa_2021.html" class="" aria-label="ESPnet Speech Enhancement Demonstration"><!--[--><!--]--> ESPnet Speech Enhancement Demonstration <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>SLU</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/slu/espnet2_2pass_slu_demo.html" class="" aria-label="ESPNET 2 pass SLU Demonstration"><!--[--><!--]--> ESPNET 2 pass SLU Demonstration <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>ST</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/st/st_demo.html" class="" aria-label="ESPnet Speech Translation Demonstration"><!--[--><!--]--> ESPnet Speech Translation Demonstration <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>Others</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/others/pretrained.html" class="" aria-label="Pretrained Model"><!--[--><!--]--> Pretrained Model <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/others/onnx_conversion_demo.html" class="" aria-label="espnet_onnx demonstration"><!--[--><!--]--> espnet_onnx demonstration <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><!--]--></ul></div></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="Tutorials"><span class="title">Tutorials</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="Tutorials"><span class="title">Tutorials</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a href="/notebook/tutorials/DataPreparation_CMU_11492_692_Spring2023(Assignment0).html" class="" aria-label="CMU 11492/11692 Spring 2023: Data preparation"><!--[--><!--]--> CMU 11492/11692 Spring 2023: Data preparation <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/notebook/tutorials/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html" class="" aria-label="CMU 11751/18781 Fall 2022: ESPnet Tutorial2 (New task)"><!--[--><!--]--> CMU 11751/18781 Fall 2022: ESPnet Tutorial2 (New task) <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/notebook/tutorials/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html" class="" aria-label="CMU 11751/18781 Fall 2022: ESPnet Tutorial"><!--[--><!--]--> CMU 11751/18781 Fall 2022: ESPnet Tutorial <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/notebook/tutorials/espnet2_tutorial_2021_CMU_11751_18781.html" class="" aria-label="CMU 11751/18781 2021: ESPnet Tutorial"><!--[--><!--]--> CMU 11751/18781 2021: ESPnet Tutorial <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/notebook/tutorials/SpeechEnhancement_CMU_11492_692_Spring2023(Assignment7).html" class="" aria-label="CMU 11492/11692 Spring 2023: Speech Enhancement"><!--[--><!--]--> CMU 11492/11692 Spring 2023: Speech Enhancement <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/notebook/tutorials/SpokenLanguageUnderstanding_CMU_11492_692_Spring2023(Assignment6).html" class="" aria-label="CMU 11492/11692 Spring 2023: Spoken Language Understanding"><!--[--><!--]--> CMU 11492/11692 Spring 2023: Spoken Language Understanding <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/notebook/tutorials/TextToSpeech_CMU_11492_692_Spring2023(Assignment8).html" class="" aria-label="CMU 11492/11692 Spring 2023: Text to Speech"><!--[--><!--]--> CMU 11492/11692 Spring 2023: Text to Speech <!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="ESPnetEasy"><span class="title">ESPnetEasy</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="ESPnetEasy"><span class="title">ESPnetEasy</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>ASR</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnetez/asr/train.html" class="" aria-label="Sample demo for ESPnet-Easy!"><!--[--><!--]--> Sample demo for ESPnet-Easy! <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnetez/asr/finetune_with_lora.html" class="" aria-label="Finetune Model with ESPnet-Easy"><!--[--><!--]--> Finetune Model with ESPnet-Easy <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnetez/asr/finetune_owsm.html" class="" aria-label="OWSM finetuning with custom dataset"><!--[--><!--]--> OWSM finetuning with custom dataset <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>TTS</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnetez/tts/tacotron2.html" class="" aria-label="TTS demo for ESPnet-Easy!"><!--[--><!--]--> TTS demo for ESPnet-Easy! <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><!--]--></ul></div></div><!--]--></nav><!--[--><!--]--><ul class="sidebar-items"><!--[--><li><p tabindex="0" class="sidebar-item sidebar-heading">ASR <!----></p><ul style="" class="sidebar-item-children"><!--[--><li><a href="/notebook/espnet2/asr/asr_cli.html" class="sidebar-item" aria-label="Speech Recognition (Recipe)"><!--[--><!--]--> Speech Recognition (Recipe) <!--[--><!--]--></a><!----></li><li><a href="/notebook/espnet2/asr/asr_library.html" class="sidebar-item" aria-label="Speech Recognition (Library)"><!--[--><!--]--> Speech Recognition (Library) <!--[--><!--]--></a><!----></li><li><a href="/notebook/espnet2/asr/espnet2_asr_realtime_demo.html" class="sidebar-item" aria-label="ESPnet2-ASR realtime demonstration"><!--[--><!--]--> ESPnet2-ASR realtime demonstration <!--[--><!--]--></a><!----></li><li><a href="/notebook/espnet2/asr/espnet2_asr_transfer_learning_demo.html" class="sidebar-item" aria-label="Use transfer learning for ASR in ESPnet2"><!--[--><!--]--> Use transfer learning for ASR in ESPnet2 <!--[--><!--]--></a><!----></li><li><a href="/notebook/espnet2/asr/espnet2_streaming_asr_demo.html" class="sidebar-item" aria-label="ESPnet2 real streaming Transformer demonstration"><!--[--><!--]--> ESPnet2 real streaming Transformer demonstration <!--[--><!--]--></a><!----></li><!--]--></ul></li><li><p tabindex="0" class="sidebar-item sidebar-heading active">TTS <!----></p><ul style="" class="sidebar-item-children"><!--[--><li><a href="/notebook/espnet2/tts/espnet2_tts_realtime_demo.html" class="sidebar-item" aria-label="ESPnet2-TTS realtime demonstration"><!--[--><!--]--> ESPnet2-TTS realtime demonstration <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/notebook/espnet2/tts/tts_cli.html" class="router-link-active router-link-exact-active router-link-active sidebar-item active" aria-label="Text-to-Speech (Recipe)"><!--[--><!--]--> Text-to-Speech (Recipe) <!--[--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/notebook/espnet2/tts/tts_cli.html#setup-envrionment" class="router-link-active router-link-exact-active sidebar-item" aria-label="Setup envrionment"><!--[--><!--]--> Setup envrionment <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/notebook/espnet2/tts/tts_cli.html#run-the-recipe" class="router-link-active router-link-exact-active sidebar-item" aria-label="Run the recipe"><!--[--><!--]--> Run the recipe <!--[--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/notebook/espnet2/tts/tts_cli.html#stage-1-data-download" class="router-link-active router-link-exact-active sidebar-item" aria-label="Stage -1: Data download"><!--[--><!--]--> Stage -1: Data download <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/notebook/espnet2/tts/tts_cli.html#stage-0-data-preparation" class="router-link-active router-link-exact-active sidebar-item" aria-label="Stage 0: Data preparation"><!--[--><!--]--> Stage 0: Data preparation <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/notebook/espnet2/tts/tts_cli.html#stage-1-feature-extration" class="router-link-active router-link-exact-active sidebar-item" aria-label="Stage 1: Feature extration"><!--[--><!--]--> Stage 1: Feature extration <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/notebook/espnet2/tts/tts_cli.html#stage-2-dictionary-and-json-preparation" class="router-link-active router-link-exact-active sidebar-item" aria-label="Stage 2: Dictionary and json preparation"><!--[--><!--]--> Stage 2: Dictionary and json preparation <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/notebook/espnet2/tts/tts_cli.html#stage-3-network-training" class="router-link-active router-link-exact-active sidebar-item" aria-label="Stage 3: Network training"><!--[--><!--]--> Stage 3: Network training <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/notebook/espnet2/tts/tts_cli.html#stage-4-network-decoding" class="router-link-active router-link-exact-active sidebar-item" aria-label="Stage 4: Network decoding"><!--[--><!--]--> Stage 4: Network decoding <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/notebook/espnet2/tts/tts_cli.html#stage-5-waveform-synthesis" class="router-link-active router-link-exact-active sidebar-item" aria-label="Stage 5: Waveform synthesis"><!--[--><!--]--> Stage 5: Waveform synthesis <!--[--><!--]--></a><!----></li><!--]--></ul></li><li><a aria-current="page" href="/notebook/espnet2/tts/tts_cli.html#next-step" class="router-link-active router-link-exact-active sidebar-item" aria-label="NEXT step"><!--[--><!--]--> NEXT step <!--[--><!--]--></a><!----></li><!--]--></ul></li><li><a href="/notebook/espnet2/tts/tts_realtime_demo.html" class="sidebar-item" aria-label="ESPnet real time E2E-TTS demonstration"><!--[--><!--]--> ESPnet real time E2E-TTS demonstration <!--[--><!--]--></a><!----></li><!--]--></ul></li><li><p tabindex="0" class="sidebar-item sidebar-heading">SE <!----></p><ul style="" class="sidebar-item-children"><!--[--><li><a href="/notebook/espnet2/se/se_demo.html" class="sidebar-item" aria-label="ESPnet Speech Enhancement Demonstration"><!--[--><!--]--> ESPnet Speech Enhancement Demonstration <!--[--><!--]--></a><!----></li><li><a href="/notebook/espnet2/se/espnet_se_demonstration_for_waspaa_2021.html" class="sidebar-item" aria-label="ESPnet Speech Enhancement Demonstration"><!--[--><!--]--> ESPnet Speech Enhancement Demonstration <!--[--><!--]--></a><!----></li><!--]--></ul></li><li><p tabindex="0" class="sidebar-item sidebar-heading">SLU <!----></p><ul style="" class="sidebar-item-children"><!--[--><li><a href="/notebook/espnet2/slu/espnet2_2pass_slu_demo.html" class="sidebar-item" aria-label="ESPNET 2 pass SLU Demonstration"><!--[--><!--]--> ESPNET 2 pass SLU Demonstration <!--[--><!--]--></a><!----></li><!--]--></ul></li><li><p tabindex="0" class="sidebar-item sidebar-heading">ST <!----></p><ul style="" class="sidebar-item-children"><!--[--><li><a href="/notebook/espnet2/st/st_demo.html" class="sidebar-item" aria-label="ESPnet Speech Translation Demonstration"><!--[--><!--]--> ESPnet Speech Translation Demonstration <!--[--><!--]--></a><!----></li><!--]--></ul></li><li><p tabindex="0" class="sidebar-item sidebar-heading">Others <!----></p><ul style="" class="sidebar-item-children"><!--[--><li><a href="/notebook/espnet2/others/pretrained.html" class="sidebar-item" aria-label="Pretrained Model"><!--[--><!--]--> Pretrained Model <!--[--><!--]--></a><!----></li><li><a href="/notebook/espnet2/others/onnx_conversion_demo.html" class="sidebar-item" aria-label="espnet_onnx demonstration"><!--[--><!--]--> espnet_onnx demonstration <!--[--><!--]--></a><!----></li><!--]--></ul></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="page"><!--[--><!--]--><div class="theme-default-content"><!--[--><!--]--><div><h1 id="text-to-speech-recipe" tabindex="-1"><a class="header-anchor" href="#text-to-speech-recipe"><span>Text-to-Speech (Recipe)</span></a></h1><p>This is the example notebook of how-to-run the ESPnet TTS recipe using an4 dataset.<br> You can understand the overview of TTS recipe through this notebook within an hour!</p><p>See also:</p><ul><li>Documentaion: <a href="https://espnet.github.io/espnet" target="_blank" rel="noopener noreferrer">https://espnet.github.io/espnet<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>Github: <a href="https://github.com/espnet" target="_blank" rel="noopener noreferrer">https://github.com/espnet<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul><p>Author: <a href="https://github.com/kan-bayashi" target="_blank" rel="noopener noreferrer">Tomoki Hayashi<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><p>Last update: 2019/07/25</p><h2 id="setup-envrionment" tabindex="-1"><a class="header-anchor" href="#setup-envrionment"><span>Setup envrionment</span></a></h2><p>First, let&#39;s setup the environmet to run the recipe.<br> It take around 10 minues. Please keep waiting for a while.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span># OS setup</span></span>
<span class="line"><span>!sudo apt-get install bc tree</span></span>
<span class="line"><span>!cat /etc/os-release</span></span>
<span class="line"><span></span></span>
<span class="line"><span># espnet setup</span></span>
<span class="line"><span>!git clone https://github.com/espnet/espnet</span></span>
<span class="line"><span>!cd espnet; pip install -e .</span></span>
<span class="line"><span></span></span>
<span class="line"><span># warp ctc setup</span></span>
<span class="line"><span>!git clone https://github.com/espnet/warp-ctc -b pytorch-1.1</span></span>
<span class="line"><span>!cd warp-ctc &amp;&amp; mkdir build &amp;&amp; cd build &amp;&amp; cmake .. &amp;&amp; make -j</span></span>
<span class="line"><span>!cd warp-ctc/pytorch_binding &amp;&amp; python setup.py install </span></span>
<span class="line"><span></span></span>
<span class="line"><span># kaldi setup</span></span>
<span class="line"><span>!cd /content/espnet/tools; git clone https://github.com/kaldi-asr/kaldi</span></span>
<span class="line"><span>!echo &quot;&quot; &gt; ./espnet/tools/kaldi/tools/extras/check_dependencies.sh # ignore check</span></span>
<span class="line"><span>!chmod +x ./espnet/tools/kaldi/tools/extras/check_dependencies.sh</span></span>
<span class="line"><span>!cd ./espnet/tools/kaldi/tools; make sph2pipe sclite</span></span>
<span class="line"><span>!rm -rf espnet/tools/kaldi/tools/python</span></span>
<span class="line"><span>!wget https://18-198329952-gh.circle-artifacts.com/0/home/circleci/repo/ubuntu16-featbin.tar.gz</span></span>
<span class="line"><span>!tar -xf ./ubuntu16-featbin.tar.gz # take a few minutes</span></span>
<span class="line"><span>!cp featbin/* espnet/tools/kaldi/src/featbin/</span></span>
<span class="line"><span></span></span>
<span class="line"><span># make dummy activate</span></span>
<span class="line"><span>!mkdir -p espnet/tools/venv/bin</span></span>
<span class="line"><span>!touch espnet/tools/venv/bin/activate</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="run-the-recipe" tabindex="-1"><a class="header-anchor" href="#run-the-recipe"><span>Run the recipe</span></a></h2><p>Now ready to run the recipe!<br> We use the most simplest recipe <code>egs/an4/tts1</code> as an example.</p><blockquote><p>Unfortunately, <code>egs/an4/tts1</code> is too small to generate reasonable speech.<br> But you can understand the flow or TTS recipe through this recipe since all of the TTS recipes has the exactly same flow.</p></blockquote><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span># Let&#39;s go to an4 recipe!</span></span>
<span class="line"><span>import os</span></span>
<span class="line"><span>os.chdir(&quot;/content/espnet/egs/an4/tts1&quot;)</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Before running the recipe, let us check the recipe structure.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!tree -L 1</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>Each recipe has the same structure and files.</p><ul><li><strong>run.sh</strong>: Main script of the recipe. Once you run this script, all of the processing will be conducted from data download, preparation, feature extraction, training, and decoding.</li><li><strong>cmd.sh</strong>: Command configuration source file about how-to-run each processing. You can modify this script if you want to run the script through job control system e.g. Slurm or Torque.</li><li><strong>path.sh</strong>: Path configuration source file. Basically, we do not have to touch.</li><li><strong>conf/</strong>: Directory containing configuration files.</li><li><strong>local/</strong>: Directory containing the recipe-specific scripts e.g. data preparation.</li><li><strong>steps/</strong> and <strong>utils/</strong>: Directory containing kaldi tools.</li></ul><p>Main script <strong>run.sh</strong> consists of several stages:</p><ul><li><strong>stage -1</strong>: Download data if the data is available online.</li><li><strong>stage 0</strong>: Prepare data to make kaldi-stype data directory.</li><li><strong>stage 1</strong>: Extract feature vector, calculate statistics, and perform normalization.</li><li><strong>stage 2</strong>: Prepare a dictionary and make json files for training.</li><li><strong>stage 3</strong>: Train the E2E-TTS network.</li><li><strong>stage 4</strong>: Decode mel-spectrogram using the trained network.</li><li><strong>stage 5</strong>: Generate a waveform from a generated mel-spectrogram using Griffin-Lim.</li></ul><p>Currently, we support the following networks:</p><ul><li>Tacotron2: <a href="https://arxiv.org/abs/1712.05884" target="_blank" rel="noopener noreferrer">Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>Transformer: <a href="https://arxiv.org/pdf/1809.08895.pdf" target="_blank" rel="noopener noreferrer">Neural Speech Synthesis with Transformer Network<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li>FastSpeech: <a href="https://arxiv.org/pdf/1905.09263.pdf" target="_blank" rel="noopener noreferrer">FastSpeech: Fast, Robust and Controllable Text to Speech<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul><p>Let us check each stage step-by-step via <strong>--stage</strong> and <strong>--stop_stage</strong> options!</p><h3 id="stage-1-data-download" tabindex="-1"><a class="header-anchor" href="#stage-1-data-download"><span>Stage -1: Data download</span></a></h3><p>This stage downloads dataset if the dataset is available online.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!./run.sh --stage -1 --stop_stage -1</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!tree -L 1</span></span>
<span class="line"><span>!ls downloads/</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>You can see <strong>downloads</strong> directory is cretead, which containing donwloaded an4 dataset.</p><h3 id="stage-0-data-preparation" tabindex="-1"><a class="header-anchor" href="#stage-0-data-preparation"><span>Stage 0: Data preparation</span></a></h3><p>This stage creates kaldi-style data directories.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!./run.sh --stage 0 --stop_stage 0</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!tree -L 1 data</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>Through the data preparation stage, kaldi-style data directories will be created.<br> Here, <strong>data/train/</strong> is corresponding to training set, and <strong>data/test</strong> is corresponding to evaluation set.<br> Each directory has the same following files:</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!ls data/*</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>The above four files are all we have to prepare to create new recipes.<br> Let&#39;s check each file.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!head -n 3 data/train/{wav.scp,text,utt2spk,spk2utt}</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>Each file contains the following information:</p><ul><li><strong>wav.scp</strong>: List of audio path. Each line has <code>&lt;utt_id&gt; &lt;wavfile_path or command pipe&gt;</code>. <code>&lt;utt_id&gt;</code> must be unique.</li><li><strong>text</strong>: List of transcriptions. Each line has <code>&lt;utt_id&gt; &lt;transcription&gt;</code>. In the case of TTS, we assume that <code>&lt;transcription&gt;</code> is cleaned.</li><li><strong>utt2spk</strong>: List of correspondence table between utterances and speakers. Each line has <code>&lt;utt_id&gt; &lt;speaker_id&gt;</code>.</li><li><strong>spk2utt</strong>: List of correspondence table between speakers and utterances. Each lien has <code>&lt;speaker_id&gt; &lt;utt_id&gt; ... &lt;utt_id&gt; </code>. This file can be automatically created from <strong>utt2spk</strong>.</li></ul><p>In the ESPnet, speaker information is not used for any processing.<br> Therefore, <strong>utt2spk</strong> and <strong>spk2utt</strong> can be a dummy.</p><h3 id="stage-1-feature-extration" tabindex="-1"><a class="header-anchor" href="#stage-1-feature-extration"><span>Stage 1: Feature extration</span></a></h3><p>This stage performs the following processing:</p><ol><li>Mel-spectrogram extraction</li><li>Data split into training and validation set</li><li>Statistics (mean and variance) calculation</li><li>Normalization</li></ol><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!./run.sh --stage 1 --stop_stage 1 --nj 4</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>Raw filterbanks are saved in <strong>fbank/</strong> directory with ark/scp format.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!ls fbank</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><strong>.ark</strong> is binary file and <strong>.scp</strong> contain the correspondence between <code>&lt;utt_id&gt;</code> and <code>&lt;path_in_ark&gt;</code>.<br> Since feature extraction can be performed for split small sets in parallel, raw_fbank is split into <code>raw_fbank_*.{1..N}.{scp,ark}.</code></p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!head -n 3 fbank/raw_fbank_train.1.scp</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>These files can be loaded in python via <strong>kaldiio</strong> as follows:</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>import kaldiio</span></span>
<span class="line"><span>import matplotlib.pyplot as plt</span></span>
<span class="line"><span></span></span>
<span class="line"><span># load scp file</span></span>
<span class="line"><span>scp_dict = kaldiio.load_scp(&quot;fbank/raw_fbank_train.1.scp&quot;)</span></span>
<span class="line"><span>for key in scp_dict:</span></span>
<span class="line"><span>    plt.imshow(scp_dict[key].T[::-1])</span></span>
<span class="line"><span>    plt.title(key)</span></span>
<span class="line"><span>    plt.colorbar()</span></span>
<span class="line"><span>    plt.show()</span></span>
<span class="line"><span>    break</span></span>
<span class="line"><span>    </span></span>
<span class="line"><span># load ark file</span></span>
<span class="line"><span>ark_generator = kaldiio.load_ark(&quot;fbank/raw_fbank_train.1.ark&quot;)</span></span>
<span class="line"><span>for key, array in ark_generator:</span></span>
<span class="line"><span>    plt.imshow(array.T[::-1])</span></span>
<span class="line"><span>    plt.title(key)</span></span>
<span class="line"><span>    plt.colorbar()</span></span>
<span class="line"><span>    plt.show()</span></span>
<span class="line"><span>    break</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>After raw mel-spectrogram extraction, some files are added in <strong>data/train/</strong>.<br><strong>feats.scp</strong> is concatenated scp file of <strong>fbank/raw_fbank_train.{1..N}.scp</strong>.<br><strong>utt2num_frames</strong> has the number of feature frames of each <code>&lt;utt_id&gt;</code>.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!ls data/train</span></span>
<span class="line"><span>!head -n 3 data/train/{feats.scp,utt2num_frames}</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>And <strong>data/train/</strong> directory is split into two directory:</p><ul><li><strong>data/train_nodev/</strong>: data directory for training</li><li><strong>data/train_dev/</strong>: data directory for validation</li></ul><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!ls data</span></span>
<span class="line"><span>!ls data/train_*</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>You can find <strong>cmvn.ark</strong> in <strong>data/train_nodev</strong>, which is the calculated statistics file.<br> This file also can be loaded in python via kaldiio.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span># load cmvn.ark file (Be careful not load_ark, but load_mat)</span></span>
<span class="line"><span>cmvn = kaldiio.load_mat(&quot;data/train_nodev/cmvn.ark&quot;)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># cmvn consists of mean and variance, the last dimension of mean represents the number of frames.</span></span>
<span class="line"><span>print(&quot;cmvn shape = &quot;+ str(cmvn.shape))</span></span>
<span class="line"><span></span></span>
<span class="line"><span># calculate mean and variance</span></span>
<span class="line"><span>mu = cmvn[0, :-1] / cmvn[0, -1]</span></span>
<span class="line"><span>var = cmvn[1, :-1] / cmvn[0, -1]</span></span>
<span class="line"><span></span></span>
<span class="line"><span># show mean</span></span>
<span class="line"><span>print(&quot;mean = &quot; + str(mu))</span></span>
<span class="line"><span>print(&quot;variance = &quot; + str(var))</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Normalzed features for training, validation and evaluation set are dumped in <strong>dump/{train_nodev,train_dev,test}/</strong>.<br> There ark and scp can be loaded as the same as the above procedure.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!ls dump/*</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h3 id="stage-2-dictionary-and-json-preparation" tabindex="-1"><a class="header-anchor" href="#stage-2-dictionary-and-json-preparation"><span>Stage 2: Dictionary and json preparation</span></a></h3><p>This stage creates dictrionary from <strong>data/train_nodev/text</strong> and makes json file for training.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!./run.sh --stage 2 --stop_stage 2</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>Dictrionary file will be created in <strong>data/lang_1char/</strong>.<br> Dictionary file consists of <code>&lt;token&gt;</code> <code>&lt;token index&gt;</code>.<br> Here, <code>&lt;token index&gt;</code> starts from 1 because 0 is used as padding index.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!ls data</span></span>
<span class="line"><span>!cat data/lang_1char/train_nodev_units.txt</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>Json file will be created for training / validation /evaludation sets and they are saved as <strong>dump/{train_nodev,train_dev,test}/data.json</strong>.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!ls dump/*/*.json</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>Each json file contains all of the information in the data directory.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!head -n 27 dump/train_nodev/data.json</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><ul><li>&quot;shape&quot;: Shape of the input or output sequence. Here input shape [63, 80] represents the number of frames = 63 and the dimension of mel-spectrogram = 80.</li><li>&quot;text&quot;: Original transcription.</li><li>&quot;token&quot;: Token sequence of original transcription.</li><li>&quot;tokenid&quot; Token id sequence of original transcription, which is converted using the dictionary.</li></ul><p>Now ready to start training!</p><h3 id="stage-3-network-training" tabindex="-1"><a class="header-anchor" href="#stage-3-network-training"><span>Stage 3: Network training</span></a></h3><p>This stage performs training of the network.<br> Network training configurations are written as <strong>.yaml</strong> format file.<br> Let us check the default cofiguration <strong>conf/train_pytroch_tacotron2.yaml</strong>.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!cat conf/train_pytorch_tacotron2.yaml</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>You can modify this configuration file to change the hyperparameters.<br> Here, let&#39;s change the number of epochs for this demonstration.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span># TODO(kan-bayashi): Change here to use change_yaml.py</span></span>
<span class="line"><span>!cat conf/train_pytorch_tacotron2.yaml | sed -e &quot;s/epochs: 50/epochs: 3/g&quot; &gt; conf/train_pytorch_tacotron2_sample.yaml</span></span>
<span class="line"><span>!cat conf/train_pytorch_tacotron2_sample.yaml</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Let&#39;s train the network.<br> You can specify the config file via <strong>--train_config</strong> option. It takes several minutes.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!./run.sh --stage 3 --stop_stage 3 --train_config conf/train_pytorch_tacotron2_sample.yaml --verbose 1</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>You can see the training log in <code>exp/train_*/train.log</code>.</p><p>The models are saved in <code>exp/train_*/results/</code> directory.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!ls exp/train_nodev_pytorch_train_pytorch_tacotron2_sample/{results,results/att_ws}</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><code>exp/train_*/results/*.png</code> are the figures of training curve.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>from IPython.display import Image, display_png</span></span>
<span class="line"><span>print(&quot;all loss curve&quot;)</span></span>
<span class="line"><span>display_png(Image(&quot;exp/train_nodev_pytorch_train_pytorch_tacotron2_sample/results/all_loss.png&quot;))</span></span>
<span class="line"><span>print(&quot;l1 loss curve&quot;)</span></span>
<span class="line"><span>display_png(Image(&quot;exp/train_nodev_pytorch_train_pytorch_tacotron2_sample/results/l1_loss.png&quot;))</span></span>
<span class="line"><span>print(&quot;mse loss curve&quot;)</span></span>
<span class="line"><span>display_png(Image(&quot;exp/train_nodev_pytorch_train_pytorch_tacotron2_sample/results/mse_loss.png&quot;))</span></span>
<span class="line"><span>print(&quot;bce loss curve&quot;)</span></span>
<span class="line"><span>display_png(Image(&quot;exp/train_nodev_pytorch_train_pytorch_tacotron2_sample/results/bce_loss.png&quot;))</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><code>exp/train_*/results/att_ws/.png</code> are the figures of attention weights in each epoch.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>print(&quot;Attention weights of initial epoch&quot;)</span></span>
<span class="line"><span>display_png(Image(&quot;exp/train_nodev_pytorch_train_pytorch_tacotron2_sample/results/att_ws/fash-cen1-b.ep.1.png&quot;))</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p><code>exp/train_*/results/model.loss.best</code> contains only the model parameters.<br> On the other hand, <code>exp/train_*/results/snapshot</code> contains the model parameters, optimizer states, and iterator states.<br> So you can restart from the training by specifying the snapshot file with <strong>--resume</strong> option.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span># resume training from snapshot.ep.2</span></span>
<span class="line"><span>!./run.sh --stage 3 --stop_stage 3 --train_config conf/train_pytorch_tacotron2_sample.yaml --resume exp/train_nodev_pytorch_train_pytorch_tacotron2_sample/results/snapshot.ep.2 --verbose 1</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!cat exp/train_nodev_pytorch_train_pytorch_tacotron2_sample/train.log</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>Also, we support tensorboard.<br> You can see the training log through tensorboard.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>%load_ext tensorboard</span></span>
<span class="line"><span>%tensorboard --logdir tensorboard/train_nodev_pytorch_train_pytorch_tacotron2_sample/</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="stage-4-network-decoding" tabindex="-1"><a class="header-anchor" href="#stage-4-network-decoding"><span>Stage 4: Network decoding</span></a></h3><p>This stage performs decoding using the trained model to generate mel-spectrogram from a given text.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!./run.sh --stage 4 --stop_stage 4 --nj 8 --train_config conf/train_pytorch_tacotron2_sample.yaml </span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>Generated features are saved as ark/scp format.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!ls exp/train_nodev_pytorch_train_pytorch_tacotron2_sample/outputs_model.loss.best_decode/*</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>We can specify the model or snapshot to be used for decoding via <strong>--model</strong>.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!./run.sh --stage 4 --stop_stage 4 --nj 8 --train_config conf/train_pytorch_tacotron2_sample.yaml --model snapshot.ep.2</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!ls exp/train_nodev_pytorch_train_pytorch_tacotron2_sample/outputs_snapshot.ep.2_decode/*</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h3 id="stage-5-waveform-synthesis" tabindex="-1"><a class="header-anchor" href="#stage-5-waveform-synthesis"><span>Stage 5: Waveform synthesis</span></a></h3><p>Finally, in this stage, we generate waveform using Grrifin-Lim algorithm.<br> First, we perform de-normalization to convert the generated mel-spectrogram into the original scale.<br> Then we apply Grrifin-Lim algorithm to restore phase components and apply inverse STFT to generate waveforms.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!./run.sh --stage 5 --stop_stage 5 --nj 8 --train_config conf/train_pytorch_tacotron2_sample.yaml --griffin_lim_iters 50</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>Generated wav files are saved in <code>exp/train_nodev_pytorch_train_pytorch_tacotron2_sample/outputs_model.loss.best_decode_denorm/*/wav</code></p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!ls exp/train_nodev_pytorch_train_pytorch_tacotron2_sample/outputs_model.loss.best_decode_denorm/*/wav</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>!tree -L 3</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h2 id="next-step" tabindex="-1"><a class="header-anchor" href="#next-step"><span>NEXT step</span></a></h2><ul><li>Try pretrained model to generate speech.</li><li>Try a large single speaker dataset recipe <strong>egs/ljspeech/tts1</strong>.</li><li>Try a large multi-speaker recipe <strong>egs/libritts/tts1</strong>.</li><li>Make the original recipe using your own dataset.</li></ul></div><!--[--><!--]--></div><footer class="page-meta"><!----><!----><!----></footer><nav class="page-nav" aria-label="page navigation"><p class="inner"><span class="prev"><a href="/notebook/espnet2/tts/espnet2_tts_realtime_demo.html" class="" aria-label="ESPnet2-TTS realtime demonstration"><!--[--><!--]--> ESPnet2-TTS realtime demonstration <!--[--><!--]--></a></span><span class="next"><a href="/notebook/espnet2/tts/tts_realtime_demo.html" class="" aria-label="ESPnet real time E2E-TTS demonstration"><!--[--><!--]--> ESPnet real time E2E-TTS demonstration <!--[--><!--]--></a></span></p></nav><!--[--><!--]--></main><!--]--></div><!----><!--]--></div>
    <script type="module" src="/notebook/assets/app-FOR18dDf.js" defer></script>
  </body>
</html>
