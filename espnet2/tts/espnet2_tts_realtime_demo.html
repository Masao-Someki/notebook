<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.2" />
    <style>
      :root {
        --c-bg: #fff;
      }
      html.dark {
        --c-bg: #22272e;
      }
      html,
      body {
        background-color: var(--c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem('vuepress-color-scheme')
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia('(prefers-color-scheme: dark)').matches
      if (userMode === 'dark' || (userMode !== 'light' && systemDarkMode)) {
        document.documentElement.classList.toggle('dark', true)
      }
    </script>
    <link rel="manifest" href="/manifest.webmanifest"><meta name="application-name" content="Example"><meta name="apple-mobile-web-app-title" content="Example"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="msapplication-TileColor" content="#3eaf7c"><meta name="theme-color" content="#3eaf7c"><title>ESPnet2-TTS realtime demonstration | ESPnet-Example</title><meta name="description" content="Example notebooks for ESPnet">
    <link rel="preload" href="/notebook/assets/style-cp41dQ25.css" as="style"><link rel="stylesheet" href="/notebook/assets/style-cp41dQ25.css">
    <link rel="modulepreload" href="/notebook/assets/app-FOR18dDf.js"><link rel="modulepreload" href="/notebook/assets/espnet2_tts_realtime_demo.html-NCcWLTBY.js"><link rel="modulepreload" href="/notebook/assets/espnet2_tts_realtime_demo.html-9h1FXENI.js">
    <link rel="prefetch" href="/notebook/assets/index.html-XAvCBsD6.js" as="script"><link rel="prefetch" href="/notebook/assets/DataPreparation_CMU_11492_692_Spring2023(Assignment0).html-KBtpWdkS.js" as="script"><link rel="prefetch" href="/notebook/assets/SpeechEnhancement_CMU_11492_692_Spring2023(Assignment7).html-ojQTonzi.js" as="script"><link rel="prefetch" href="/notebook/assets/SpokenLanguageUnderstanding_CMU_11492_692_Spring2023(Assignment6).html-k7t3PiyY.js" as="script"><link rel="prefetch" href="/notebook/assets/TextToSpeech_CMU_11492_692_Spring2023(Assignment8).html-mugYinQi.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html-xjN-GwTF.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html-IaNcm8K-.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_tutorial_2021_CMU_11751_18781.html-IMfnLI01.js" as="script"><link rel="prefetch" href="/notebook/assets/asr_cli.html-JH3saHIF.js" as="script"><link rel="prefetch" href="/notebook/assets/asr_library.html-nD4wSonE.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_asr_realtime_demo.html-31qj-nF8.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_asr_transfer_learning_demo.html-K8AGvfnJ.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_streaming_asr_demo.html-NgcmLWnC.js" as="script"><link rel="prefetch" href="/notebook/assets/onnx_conversion_demo.html-wfKipc9w.js" as="script"><link rel="prefetch" href="/notebook/assets/pretrained.html--Y7vPVCq.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet_se_demonstration_for_waspaa_2021.html-_RqduImg.js" as="script"><link rel="prefetch" href="/notebook/assets/se_demo.html-zhHwqNB_.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_2pass_slu_demo.html-SOe7ZUtq.js" as="script"><link rel="prefetch" href="/notebook/assets/st_demo.html-_JBPLyfl.js" as="script"><link rel="prefetch" href="/notebook/assets/tts_cli.html-OLkBd5Fu.js" as="script"><link rel="prefetch" href="/notebook/assets/tts_realtime_demo.html-Bgn0MtVH.js" as="script"><link rel="prefetch" href="/notebook/assets/finetune_owsm.html-oRbSv_3K.js" as="script"><link rel="prefetch" href="/notebook/assets/finetune_with_lora.html-53DWrWT9.js" as="script"><link rel="prefetch" href="/notebook/assets/train.html-ZtrUU739.js" as="script"><link rel="prefetch" href="/notebook/assets/tacotron2.html-lMDTfHXx.js" as="script"><link rel="prefetch" href="/notebook/assets/404.html-6Yl8cQE3.js" as="script"><link rel="prefetch" href="/notebook/assets/index.html-Fa1mvKNA.js" as="script"><link rel="prefetch" href="/notebook/assets/DataPreparation_CMU_11492_692_Spring2023(Assignment0).html-yZnfE8Rl.js" as="script"><link rel="prefetch" href="/notebook/assets/SpeechEnhancement_CMU_11492_692_Spring2023(Assignment7).html-EtOqTzx1.js" as="script"><link rel="prefetch" href="/notebook/assets/SpokenLanguageUnderstanding_CMU_11492_692_Spring2023(Assignment6).html-3QqySz0B.js" as="script"><link rel="prefetch" href="/notebook/assets/TextToSpeech_CMU_11492_692_Spring2023(Assignment8).html-oKNm4LpP.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html-4zeeKKut.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html-Xne2M8JW.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_tutorial_2021_CMU_11751_18781.html-HhdidVDJ.js" as="script"><link rel="prefetch" href="/notebook/assets/asr_cli.html-knKjgurg.js" as="script"><link rel="prefetch" href="/notebook/assets/asr_library.html-Kz7KwH4E.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_asr_realtime_demo.html-RYvF9e8R.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_asr_transfer_learning_demo.html-IksoduPb.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_streaming_asr_demo.html-6EF7rYtq.js" as="script"><link rel="prefetch" href="/notebook/assets/onnx_conversion_demo.html-1dXBgI7d.js" as="script"><link rel="prefetch" href="/notebook/assets/pretrained.html-bRY7ZLad.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet_se_demonstration_for_waspaa_2021.html-53aPYjLT.js" as="script"><link rel="prefetch" href="/notebook/assets/se_demo.html-0y7hJZOb.js" as="script"><link rel="prefetch" href="/notebook/assets/espnet2_2pass_slu_demo.html-LPf_aa6M.js" as="script"><link rel="prefetch" href="/notebook/assets/st_demo.html-GjLoLXxU.js" as="script"><link rel="prefetch" href="/notebook/assets/tts_cli.html-Elg6sapX.js" as="script"><link rel="prefetch" href="/notebook/assets/tts_realtime_demo.html-wTutqUQW.js" as="script"><link rel="prefetch" href="/notebook/assets/finetune_owsm.html-BKHMtCfm.js" as="script"><link rel="prefetch" href="/notebook/assets/finetune_with_lora.html-h3VNWfNm.js" as="script"><link rel="prefetch" href="/notebook/assets/train.html-zSf_6N6D.js" as="script"><link rel="prefetch" href="/notebook/assets/tacotron2.html-gzrp5q7X.js" as="script"><link rel="prefetch" href="/notebook/assets/404.html-8hkKDKOa.js" as="script"><link rel="prefetch" href="/notebook/assets/NpmBadge-ZlH3swud.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="theme-container"><!--[--><header class="navbar"><div class="toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a href="/notebook/" class=""><img class="logo" src="/notebook/images/espnet_logo1.png" alt="ESPnet-Example"><span class="site-name can-hide" aria-hidden="true">ESPnet-Example</span></a></span><div class="navbar-items-wrapper" style=""><!--[--><!--]--><nav class="navbar-items can-hide" aria-label="site navigation"><!--[--><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="ESPnet2"><span class="title">ESPnet2</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="ESPnet2"><span class="title">ESPnet2</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>ASR</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/asr/asr_cli.html" class="" aria-label="Speech Recognition (Recipe)"><!--[--><!--]--> Speech Recognition (Recipe) <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/asr/asr_library.html" class="" aria-label="Speech Recognition (Library)"><!--[--><!--]--> Speech Recognition (Library) <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/asr/espnet2_asr_realtime_demo.html" class="" aria-label="ESPnet2-ASR realtime demonstration"><!--[--><!--]--> ESPnet2-ASR realtime demonstration <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/asr/espnet2_asr_transfer_learning_demo.html" class="" aria-label="Use transfer learning for ASR in ESPnet2"><!--[--><!--]--> Use transfer learning for ASR in ESPnet2 <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/asr/espnet2_streaming_asr_demo.html" class="" aria-label="ESPnet2 real streaming Transformer demonstration"><!--[--><!--]--> ESPnet2 real streaming Transformer demonstration <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>TTS</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a aria-current="page" href="/notebook/espnet2/tts/espnet2_tts_realtime_demo.html" class="router-link-active router-link-exact-active router-link-active" aria-label="ESPnet2-TTS realtime demonstration"><!--[--><!--]--> ESPnet2-TTS realtime demonstration <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/tts/tts_cli.html" class="" aria-label="Text-to-Speech (Recipe)"><!--[--><!--]--> Text-to-Speech (Recipe) <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/tts/tts_realtime_demo.html" class="" aria-label="ESPnet real time E2E-TTS demonstration"><!--[--><!--]--> ESPnet real time E2E-TTS demonstration <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>SE</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/se/se_demo.html" class="" aria-label="ESPnet Speech Enhancement Demonstration"><!--[--><!--]--> ESPnet Speech Enhancement Demonstration <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/se/espnet_se_demonstration_for_waspaa_2021.html" class="" aria-label="ESPnet Speech Enhancement Demonstration"><!--[--><!--]--> ESPnet Speech Enhancement Demonstration <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>SLU</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/slu/espnet2_2pass_slu_demo.html" class="" aria-label="ESPNET 2 pass SLU Demonstration"><!--[--><!--]--> ESPNET 2 pass SLU Demonstration <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>ST</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/st/st_demo.html" class="" aria-label="ESPnet Speech Translation Demonstration"><!--[--><!--]--> ESPnet Speech Translation Demonstration <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>Others</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/others/pretrained.html" class="" aria-label="Pretrained Model"><!--[--><!--]--> Pretrained Model <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/others/onnx_conversion_demo.html" class="" aria-label="espnet_onnx demonstration"><!--[--><!--]--> espnet_onnx demonstration <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><!--]--></ul></div></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="Tutorials"><span class="title">Tutorials</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="Tutorials"><span class="title">Tutorials</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a href="/notebook/tutorials/DataPreparation_CMU_11492_692_Spring2023(Assignment0).html" class="" aria-label="CMU 11492/11692 Spring 2023: Data preparation"><!--[--><!--]--> CMU 11492/11692 Spring 2023: Data preparation <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/notebook/tutorials/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html" class="" aria-label="CMU 11751/18781 Fall 2022: ESPnet Tutorial2 (New task)"><!--[--><!--]--> CMU 11751/18781 Fall 2022: ESPnet Tutorial2 (New task) <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/notebook/tutorials/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html" class="" aria-label="CMU 11751/18781 Fall 2022: ESPnet Tutorial"><!--[--><!--]--> CMU 11751/18781 Fall 2022: ESPnet Tutorial <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/notebook/tutorials/espnet2_tutorial_2021_CMU_11751_18781.html" class="" aria-label="CMU 11751/18781 2021: ESPnet Tutorial"><!--[--><!--]--> CMU 11751/18781 2021: ESPnet Tutorial <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/notebook/tutorials/SpeechEnhancement_CMU_11492_692_Spring2023(Assignment7).html" class="" aria-label="CMU 11492/11692 Spring 2023: Speech Enhancement"><!--[--><!--]--> CMU 11492/11692 Spring 2023: Speech Enhancement <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/notebook/tutorials/SpokenLanguageUnderstanding_CMU_11492_692_Spring2023(Assignment6).html" class="" aria-label="CMU 11492/11692 Spring 2023: Spoken Language Understanding"><!--[--><!--]--> CMU 11492/11692 Spring 2023: Spoken Language Understanding <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/notebook/tutorials/TextToSpeech_CMU_11492_692_Spring2023(Assignment8).html" class="" aria-label="CMU 11492/11692 Spring 2023: Text to Speech"><!--[--><!--]--> CMU 11492/11692 Spring 2023: Text to Speech <!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="ESPnetEasy"><span class="title">ESPnetEasy</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="ESPnetEasy"><span class="title">ESPnetEasy</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>ASR</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnetez/asr/train.html" class="" aria-label="Sample demo for ESPnet-Easy!"><!--[--><!--]--> Sample demo for ESPnet-Easy! <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnetez/asr/finetune_with_lora.html" class="" aria-label="Finetune Model with ESPnet-Easy"><!--[--><!--]--> Finetune Model with ESPnet-Easy <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnetez/asr/finetune_owsm.html" class="" aria-label="OWSM finetuning with custom dataset"><!--[--><!--]--> OWSM finetuning with custom dataset <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>TTS</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnetez/tts/tacotron2.html" class="" aria-label="TTS demo for ESPnet-Easy!"><!--[--><!--]--> TTS demo for ESPnet-Easy! <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><!--]--></ul></div></div><!--]--></nav><!--[--><!--]--><button class="toggle-color-mode-button" title="toggle color mode"><svg style="" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg style="display:none;" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><form class="search-box" role="search"><input type="search" placeholder="Search" autocomplete="off" spellcheck="false" value><!----></form></div></header><!--]--><div class="sidebar-mask"></div><!--[--><aside class="sidebar"><nav class="navbar-items" aria-label="site navigation"><!--[--><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="ESPnet2"><span class="title">ESPnet2</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="ESPnet2"><span class="title">ESPnet2</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>ASR</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/asr/asr_cli.html" class="" aria-label="Speech Recognition (Recipe)"><!--[--><!--]--> Speech Recognition (Recipe) <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/asr/asr_library.html" class="" aria-label="Speech Recognition (Library)"><!--[--><!--]--> Speech Recognition (Library) <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/asr/espnet2_asr_realtime_demo.html" class="" aria-label="ESPnet2-ASR realtime demonstration"><!--[--><!--]--> ESPnet2-ASR realtime demonstration <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/asr/espnet2_asr_transfer_learning_demo.html" class="" aria-label="Use transfer learning for ASR in ESPnet2"><!--[--><!--]--> Use transfer learning for ASR in ESPnet2 <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/asr/espnet2_streaming_asr_demo.html" class="" aria-label="ESPnet2 real streaming Transformer demonstration"><!--[--><!--]--> ESPnet2 real streaming Transformer demonstration <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>TTS</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a aria-current="page" href="/notebook/espnet2/tts/espnet2_tts_realtime_demo.html" class="router-link-active router-link-exact-active router-link-active" aria-label="ESPnet2-TTS realtime demonstration"><!--[--><!--]--> ESPnet2-TTS realtime demonstration <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/tts/tts_cli.html" class="" aria-label="Text-to-Speech (Recipe)"><!--[--><!--]--> Text-to-Speech (Recipe) <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/tts/tts_realtime_demo.html" class="" aria-label="ESPnet real time E2E-TTS demonstration"><!--[--><!--]--> ESPnet real time E2E-TTS demonstration <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>SE</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/se/se_demo.html" class="" aria-label="ESPnet Speech Enhancement Demonstration"><!--[--><!--]--> ESPnet Speech Enhancement Demonstration <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/se/espnet_se_demonstration_for_waspaa_2021.html" class="" aria-label="ESPnet Speech Enhancement Demonstration"><!--[--><!--]--> ESPnet Speech Enhancement Demonstration <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>SLU</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/slu/espnet2_2pass_slu_demo.html" class="" aria-label="ESPNET 2 pass SLU Demonstration"><!--[--><!--]--> ESPNET 2 pass SLU Demonstration <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>ST</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/st/st_demo.html" class="" aria-label="ESPnet Speech Translation Demonstration"><!--[--><!--]--> ESPnet Speech Translation Demonstration <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>Others</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/others/pretrained.html" class="" aria-label="Pretrained Model"><!--[--><!--]--> Pretrained Model <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnet2/others/onnx_conversion_demo.html" class="" aria-label="espnet_onnx demonstration"><!--[--><!--]--> espnet_onnx demonstration <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><!--]--></ul></div></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="Tutorials"><span class="title">Tutorials</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="Tutorials"><span class="title">Tutorials</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a href="/notebook/tutorials/DataPreparation_CMU_11492_692_Spring2023(Assignment0).html" class="" aria-label="CMU 11492/11692 Spring 2023: Data preparation"><!--[--><!--]--> CMU 11492/11692 Spring 2023: Data preparation <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/notebook/tutorials/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html" class="" aria-label="CMU 11751/18781 Fall 2022: ESPnet Tutorial2 (New task)"><!--[--><!--]--> CMU 11751/18781 Fall 2022: ESPnet Tutorial2 (New task) <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/notebook/tutorials/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html" class="" aria-label="CMU 11751/18781 Fall 2022: ESPnet Tutorial"><!--[--><!--]--> CMU 11751/18781 Fall 2022: ESPnet Tutorial <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/notebook/tutorials/espnet2_tutorial_2021_CMU_11751_18781.html" class="" aria-label="CMU 11751/18781 2021: ESPnet Tutorial"><!--[--><!--]--> CMU 11751/18781 2021: ESPnet Tutorial <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/notebook/tutorials/SpeechEnhancement_CMU_11492_692_Spring2023(Assignment7).html" class="" aria-label="CMU 11492/11692 Spring 2023: Speech Enhancement"><!--[--><!--]--> CMU 11492/11692 Spring 2023: Speech Enhancement <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/notebook/tutorials/SpokenLanguageUnderstanding_CMU_11492_692_Spring2023(Assignment6).html" class="" aria-label="CMU 11492/11692 Spring 2023: Spoken Language Understanding"><!--[--><!--]--> CMU 11492/11692 Spring 2023: Spoken Language Understanding <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/notebook/tutorials/TextToSpeech_CMU_11492_692_Spring2023(Assignment8).html" class="" aria-label="CMU 11492/11692 Spring 2023: Text to Speech"><!--[--><!--]--> CMU 11492/11692 Spring 2023: Text to Speech <!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="ESPnetEasy"><span class="title">ESPnetEasy</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="ESPnetEasy"><span class="title">ESPnetEasy</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>ASR</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnetez/asr/train.html" class="" aria-label="Sample demo for ESPnet-Easy!"><!--[--><!--]--> Sample demo for ESPnet-Easy! <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnetez/asr/finetune_with_lora.html" class="" aria-label="Finetune Model with ESPnet-Easy"><!--[--><!--]--> Finetune Model with ESPnet-Easy <!--[--><!--]--></a></li><li class="navbar-dropdown-subitem"><a href="/notebook/espnetez/asr/finetune_owsm.html" class="" aria-label="OWSM finetuning with custom dataset"><!--[--><!--]--> OWSM finetuning with custom dataset <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><li class="navbar-dropdown-item"><!--[--><h4 class="navbar-dropdown-subtitle"><span>TTS</span></h4><ul class="navbar-dropdown-subitem-wrapper"><!--[--><li class="navbar-dropdown-subitem"><a href="/notebook/espnetez/tts/tacotron2.html" class="" aria-label="TTS demo for ESPnet-Easy!"><!--[--><!--]--> TTS demo for ESPnet-Easy! <!--[--><!--]--></a></li><!--]--></ul><!--]--></li><!--]--></ul></div></div><!--]--></nav><!--[--><!--]--><ul class="sidebar-items"><!--[--><li><p tabindex="0" class="sidebar-item sidebar-heading">ASR <!----></p><ul style="" class="sidebar-item-children"><!--[--><li><a href="/notebook/espnet2/asr/asr_cli.html" class="sidebar-item" aria-label="Speech Recognition (Recipe)"><!--[--><!--]--> Speech Recognition (Recipe) <!--[--><!--]--></a><!----></li><li><a href="/notebook/espnet2/asr/asr_library.html" class="sidebar-item" aria-label="Speech Recognition (Library)"><!--[--><!--]--> Speech Recognition (Library) <!--[--><!--]--></a><!----></li><li><a href="/notebook/espnet2/asr/espnet2_asr_realtime_demo.html" class="sidebar-item" aria-label="ESPnet2-ASR realtime demonstration"><!--[--><!--]--> ESPnet2-ASR realtime demonstration <!--[--><!--]--></a><!----></li><li><a href="/notebook/espnet2/asr/espnet2_asr_transfer_learning_demo.html" class="sidebar-item" aria-label="Use transfer learning for ASR in ESPnet2"><!--[--><!--]--> Use transfer learning for ASR in ESPnet2 <!--[--><!--]--></a><!----></li><li><a href="/notebook/espnet2/asr/espnet2_streaming_asr_demo.html" class="sidebar-item" aria-label="ESPnet2 real streaming Transformer demonstration"><!--[--><!--]--> ESPnet2 real streaming Transformer demonstration <!--[--><!--]--></a><!----></li><!--]--></ul></li><li><p tabindex="0" class="sidebar-item sidebar-heading active">TTS <!----></p><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/notebook/espnet2/tts/espnet2_tts_realtime_demo.html" class="router-link-active router-link-exact-active router-link-active sidebar-item active" aria-label="ESPnet2-TTS realtime demonstration"><!--[--><!--]--> ESPnet2-TTS realtime demonstration <!--[--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/notebook/espnet2/tts/espnet2_tts_realtime_demo.html#installation" class="router-link-active router-link-exact-active sidebar-item" aria-label="Installation"><!--[--><!--]--> Installation <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/notebook/espnet2/tts/espnet2_tts_realtime_demo.html#single-speaker-model-demo" class="router-link-active router-link-exact-active sidebar-item" aria-label="Single speaker model demo"><!--[--><!--]--> Single speaker model demo <!--[--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/notebook/espnet2/tts/espnet2_tts_realtime_demo.html#model-selection" class="router-link-active router-link-exact-active sidebar-item" aria-label="Model Selection"><!--[--><!--]--> Model Selection <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/notebook/espnet2/tts/espnet2_tts_realtime_demo.html#model-setup" class="router-link-active router-link-exact-active sidebar-item" aria-label="Model Setup"><!--[--><!--]--> Model Setup <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/notebook/espnet2/tts/espnet2_tts_realtime_demo.html#synthesis" class="router-link-active router-link-exact-active sidebar-item" aria-label="Synthesis"><!--[--><!--]--> Synthesis <!--[--><!--]--></a><!----></li><!--]--></ul></li><li><a aria-current="page" href="/notebook/espnet2/tts/espnet2_tts_realtime_demo.html#multi-speaker-model-demo" class="router-link-active router-link-exact-active sidebar-item" aria-label="Multi-speaker Model Demo"><!--[--><!--]--> Multi-speaker Model Demo <!--[--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/notebook/espnet2/tts/espnet2_tts_realtime_demo.html#model-selection-1" class="router-link-active router-link-exact-active sidebar-item" aria-label="Model Selection"><!--[--><!--]--> Model Selection <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/notebook/espnet2/tts/espnet2_tts_realtime_demo.html#model-setup-1" class="router-link-active router-link-exact-active sidebar-item" aria-label="Model Setup"><!--[--><!--]--> Model Setup <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/notebook/espnet2/tts/espnet2_tts_realtime_demo.html#speaker-selection" class="router-link-active router-link-exact-active sidebar-item" aria-label="Speaker selection"><!--[--><!--]--> Speaker selection <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/notebook/espnet2/tts/espnet2_tts_realtime_demo.html#synthesis-1" class="router-link-active router-link-exact-active sidebar-item" aria-label="Synthesis"><!--[--><!--]--> Synthesis <!--[--><!--]--></a><!----></li><!--]--></ul></li><!--]--></ul></li><li><a href="/notebook/espnet2/tts/tts_cli.html" class="sidebar-item" aria-label="Text-to-Speech (Recipe)"><!--[--><!--]--> Text-to-Speech (Recipe) <!--[--><!--]--></a><!----></li><li><a href="/notebook/espnet2/tts/tts_realtime_demo.html" class="sidebar-item" aria-label="ESPnet real time E2E-TTS demonstration"><!--[--><!--]--> ESPnet real time E2E-TTS demonstration <!--[--><!--]--></a><!----></li><!--]--></ul></li><li><p tabindex="0" class="sidebar-item sidebar-heading">SE <!----></p><ul style="" class="sidebar-item-children"><!--[--><li><a href="/notebook/espnet2/se/se_demo.html" class="sidebar-item" aria-label="ESPnet Speech Enhancement Demonstration"><!--[--><!--]--> ESPnet Speech Enhancement Demonstration <!--[--><!--]--></a><!----></li><li><a href="/notebook/espnet2/se/espnet_se_demonstration_for_waspaa_2021.html" class="sidebar-item" aria-label="ESPnet Speech Enhancement Demonstration"><!--[--><!--]--> ESPnet Speech Enhancement Demonstration <!--[--><!--]--></a><!----></li><!--]--></ul></li><li><p tabindex="0" class="sidebar-item sidebar-heading">SLU <!----></p><ul style="" class="sidebar-item-children"><!--[--><li><a href="/notebook/espnet2/slu/espnet2_2pass_slu_demo.html" class="sidebar-item" aria-label="ESPNET 2 pass SLU Demonstration"><!--[--><!--]--> ESPNET 2 pass SLU Demonstration <!--[--><!--]--></a><!----></li><!--]--></ul></li><li><p tabindex="0" class="sidebar-item sidebar-heading">ST <!----></p><ul style="" class="sidebar-item-children"><!--[--><li><a href="/notebook/espnet2/st/st_demo.html" class="sidebar-item" aria-label="ESPnet Speech Translation Demonstration"><!--[--><!--]--> ESPnet Speech Translation Demonstration <!--[--><!--]--></a><!----></li><!--]--></ul></li><li><p tabindex="0" class="sidebar-item sidebar-heading">Others <!----></p><ul style="" class="sidebar-item-children"><!--[--><li><a href="/notebook/espnet2/others/pretrained.html" class="sidebar-item" aria-label="Pretrained Model"><!--[--><!--]--> Pretrained Model <!--[--><!--]--></a><!----></li><li><a href="/notebook/espnet2/others/onnx_conversion_demo.html" class="sidebar-item" aria-label="espnet_onnx demonstration"><!--[--><!--]--> espnet_onnx demonstration <!--[--><!--]--></a><!----></li><!--]--></ul></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="page"><!--[--><!--]--><div class="theme-default-content"><!--[--><!--]--><div><p><a href="https://colab.research.google.com/github/espnet/notebook/blob/master/espnet2_tts_realtime_demo.ipynb" target="_blank" rel="noopener noreferrer"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"><span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><h1 id="espnet2-tts-realtime-demonstration" tabindex="-1"><a class="header-anchor" href="#espnet2-tts-realtime-demonstration"><span>ESPnet2-TTS realtime demonstration</span></a></h1><p>This notebook provides a demonstration of the realtime E2E-TTS using ESPnet2-TTS and ParallelWaveGAN repo.</p><ul><li>ESPnet2-TTS: https://github.com/espnet/espnet/tree/master/egs2/TEMPLATE/tts1</li><li>ParallelWaveGAN: https://github.com/kan-bayashi/ParallelWaveGAN</li></ul><p>Author: Tomoki Hayashi (<a href="https://github.com/kan-bayashi" target="_blank" rel="noopener noreferrer">@kan-bayashi<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>)</p><h2 id="installation" tabindex="-1"><a class="header-anchor" href="#installation"><span>Installation</span></a></h2><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span># NOTE: pip shows imcompatible errors due to preinstalled libraries but you do not need to care</span></span>
<span class="line"><span>!pip install -q espnet==202308 pypinyin==0.44.0 parallel_wavegan==0.5.4 gdown==4.4.0 espnet_model_zoo</span></span>
<span class="line"><span></span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="single-speaker-model-demo" tabindex="-1"><a class="header-anchor" href="#single-speaker-model-demo"><span>Single speaker model demo</span></a></h2><h3 id="model-selection" tabindex="-1"><a class="header-anchor" href="#model-selection"><span>Model Selection</span></a></h3><p>Please select model: English, Japanese, and Mandarin are supported.</p><p>You can try end-to-end text2wav model &amp; combination of text2mel and vocoder.<br> If you use text2wav model, you do not need to use vocoder (automatically disabled).</p><p><strong>Text2wav models</strong>:</p><ul><li>VITS</li></ul><p><strong>Text2mel models</strong>:</p><ul><li>Tacotron2</li><li>Transformer-TTS</li><li>(Conformer) FastSpeech</li><li>(Conformer) FastSpeech2</li></ul><p><strong>Vocoders</strong>:</p><ul><li>Parallel WaveGAN</li><li>Multi-band MelGAN</li><li>HiFiGAN</li><li>Style MelGAN.</li></ul><blockquote><p>The terms of use follow that of each corpus. We use the following corpora:</p></blockquote><ul><li><code>ljspeech_*</code>: LJSpeech dataset <ul><li>https://keithito.com/LJ-Speech-Dataset/</li></ul></li><li><code>jsut_*</code>: JSUT corpus <ul><li>https://sites.google.com/site/shinnosuketakamichi/publication/jsut</li></ul></li><li><code>jvs_*</code>: JVS corpus + JSUT corpus <ul><li>https://sites.google.com/site/shinnosuketakamichi/research-topics/jvs_corpus</li><li>https://sites.google.com/site/shinnosuketakamichi/publication/jsut</li></ul></li><li><code>tsukuyomi_*</code>: つくよみちゃんコーパス + JSUT corpus <ul><li>https://tyc.rei-yumesaki.net/material/corpus/</li><li>https://sites.google.com/site/shinnosuketakamichi/publication/jsut</li></ul></li><li><code>csmsc_*</code>: Chinese Standard Mandarin Speech Corpus <ul><li>https://www.data-baker.com/open_source.html</li></ul></li></ul><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>#@title Choose English model { run: &quot;auto&quot; }</span></span>
<span class="line"><span>lang = &#39;English&#39;</span></span>
<span class="line"><span>tag = &#39;kan-bayashi/ljspeech_vits&#39; #@param [&quot;kan-bayashi/ljspeech_tacotron2&quot;, &quot;kan-bayashi/ljspeech_fastspeech&quot;, &quot;kan-bayashi/ljspeech_fastspeech2&quot;, &quot;kan-bayashi/ljspeech_conformer_fastspeech2&quot;, &quot;kan-bayashi/ljspeech_joint_finetune_conformer_fastspeech2_hifigan&quot;, &quot;kan-bayashi/ljspeech_joint_train_conformer_fastspeech2_hifigan&quot;, &quot;kan-bayashi/ljspeech_vits&quot;] {type:&quot;string&quot;}</span></span>
<span class="line"><span>vocoder_tag = &quot;none&quot; #@param [&quot;none&quot;, &quot;parallel_wavegan/ljspeech_parallel_wavegan.v1&quot;, &quot;parallel_wavegan/ljspeech_full_band_melgan.v2&quot;, &quot;parallel_wavegan/ljspeech_multi_band_melgan.v2&quot;, &quot;parallel_wavegan/ljspeech_hifigan.v1&quot;, &quot;parallel_wavegan/ljspeech_style_melgan.v1&quot;] {type:&quot;string&quot;}</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>#@title Choose Japanese model { run: &quot;auto&quot; }</span></span>
<span class="line"><span>lang = &#39;Japanese&#39;</span></span>
<span class="line"><span>tag = &#39;kan-bayashi/jsut_full_band_vits_prosody&#39; #@param [&quot;kan-bayashi/jsut_tacotron2&quot;, &quot;kan-bayashi/jsut_transformer&quot;, &quot;kan-bayashi/jsut_fastspeech&quot;, &quot;kan-bayashi/jsut_fastspeech2&quot;, &quot;kan-bayashi/jsut_conformer_fastspeech2&quot;, &quot;kan-bayashi/jsut_conformer_fastspeech2_accent&quot;, &quot;kan-bayashi/jsut_conformer_fastspeech2_accent_with_pause&quot;, &quot;kan-bayashi/jsut_vits_accent_with_pause&quot;, &quot;kan-bayashi/jsut_full_band_vits_accent_with_pause&quot;, &quot;kan-bayashi/jsut_tacotron2_prosody&quot;, &quot;kan-bayashi/jsut_transformer_prosody&quot;, &quot;kan-bayashi/jsut_conformer_fastspeech2_tacotron2_prosody&quot;, &quot;kan-bayashi/jsut_vits_prosody&quot;, &quot;kan-bayashi/jsut_full_band_vits_prosody&quot;, &quot;kan-bayashi/jvs_jvs010_vits_prosody&quot;, &quot;kan-bayashi/tsukuyomi_full_band_vits_prosody&quot;] {type:&quot;string&quot;}</span></span>
<span class="line"><span>vocoder_tag = &#39;none&#39; #@param [&quot;none&quot;, &quot;parallel_wavegan/jsut_parallel_wavegan.v1&quot;, &quot;parallel_wavegan/jsut_multi_band_melgan.v2&quot;, &quot;parallel_wavegan/jsut_style_melgan.v1&quot;, &quot;parallel_wavegan/jsut_hifigan.v1&quot;] {type:&quot;string&quot;}</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>#@title Choose Mandarin model { run: &quot;auto&quot; }</span></span>
<span class="line"><span>lang = &#39;Mandarin&#39;</span></span>
<span class="line"><span>tag = &#39;kan-bayashi/csmsc_full_band_vits&#39; #@param [&quot;kan-bayashi/csmsc_tacotron2&quot;, &quot;kan-bayashi/csmsc_transformer&quot;, &quot;kan-bayashi/csmsc_fastspeech&quot;, &quot;kan-bayashi/csmsc_fastspeech2&quot;, &quot;kan-bayashi/csmsc_conformer_fastspeech2&quot;, &quot;kan-bayashi/csmsc_vits&quot;, &quot;kan-bayashi/csmsc_full_band_vits&quot;] {type: &quot;string&quot;}</span></span>
<span class="line"><span>vocoder_tag = &quot;none&quot; #@param [&quot;none&quot;, &quot;parallel_wavegan/csmsc_parallel_wavegan.v1&quot;, &quot;parallel_wavegan/csmsc_multi_band_melgan.v2&quot;, &quot;parallel_wavegan/csmsc_hifigan.v1&quot;, &quot;parallel_wavegan/csmsc_style_melgan.v1&quot;] {type:&quot;string&quot;}</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="model-setup" tabindex="-1"><a class="header-anchor" href="#model-setup"><span>Model Setup</span></a></h3><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>from espnet2.bin.tts_inference import Text2Speech</span></span>
<span class="line"><span>from espnet2.utils.types import str_or_none</span></span>
<span class="line"><span></span></span>
<span class="line"><span>text2speech = Text2Speech.from_pretrained(</span></span>
<span class="line"><span>    model_tag=str_or_none(tag),</span></span>
<span class="line"><span>    vocoder_tag=str_or_none(vocoder_tag),</span></span>
<span class="line"><span>    device=&quot;cuda&quot;,</span></span>
<span class="line"><span>    # Only for Tacotron 2 &amp; Transformer</span></span>
<span class="line"><span>    threshold=0.5,</span></span>
<span class="line"><span>    # Only for Tacotron 2</span></span>
<span class="line"><span>    minlenratio=0.0,</span></span>
<span class="line"><span>    maxlenratio=10.0,</span></span>
<span class="line"><span>    use_att_constraint=False,</span></span>
<span class="line"><span>    backward_window=1,</span></span>
<span class="line"><span>    forward_window=3,</span></span>
<span class="line"><span>    # Only for FastSpeech &amp; FastSpeech2 &amp; VITS</span></span>
<span class="line"><span>    speed_control_alpha=1.0,</span></span>
<span class="line"><span>    # Only for VITS</span></span>
<span class="line"><span>    noise_scale=0.333,</span></span>
<span class="line"><span>    noise_scale_dur=0.333,</span></span>
<span class="line"><span>)</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="synthesis" tabindex="-1"><a class="header-anchor" href="#synthesis"><span>Synthesis</span></a></h3><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>import time</span></span>
<span class="line"><span>import torch</span></span>
<span class="line"><span></span></span>
<span class="line"><span># decide the input sentence by yourself</span></span>
<span class="line"><span>print(f&quot;Input your favorite sentence in {lang}.&quot;)</span></span>
<span class="line"><span>x = input()</span></span>
<span class="line"><span></span></span>
<span class="line"><span># synthesis</span></span>
<span class="line"><span>with torch.no_grad():</span></span>
<span class="line"><span>    start = time.time()</span></span>
<span class="line"><span>    wav = text2speech(x)[&quot;wav&quot;]</span></span>
<span class="line"><span>rtf = (time.time() - start) / (len(wav) / text2speech.fs)</span></span>
<span class="line"><span>print(f&quot;RTF = {rtf:5f}&quot;)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># let us listen to generated samples</span></span>
<span class="line"><span>from IPython.display import display, Audio</span></span>
<span class="line"><span>display(Audio(wav.view(-1).cpu().numpy(), rate=text2speech.fs))</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="multi-speaker-model-demo" tabindex="-1"><a class="header-anchor" href="#multi-speaker-model-demo"><span>Multi-speaker Model Demo</span></a></h2><h3 id="model-selection-1" tabindex="-1"><a class="header-anchor" href="#model-selection-1"><span>Model Selection</span></a></h3><p>Now we provide only English multi-speaker pretrained model.</p><blockquote><p>The terms of use follow that of each corpus. We use the following corpora:</p></blockquote><ul><li><code>libritts_*</code>: LibriTTS corpus <ul><li>http://www.openslr.org/60</li></ul></li><li><code>vctk_*</code>: English Multi-speaker Corpus for CSTR Voice Cloning Toolkit <ul><li>http://www.udialogue.org/download/cstr-vctk-corpus.html</li></ul></li></ul><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>#@title English multi-speaker pretrained model { run: &quot;auto&quot; }</span></span>
<span class="line"><span>lang = &#39;English&#39;</span></span>
<span class="line"><span>tag = &#39;kan-bayashi/vctk_full_band_multi_spk_vits&#39; #@param [&quot;kan-bayashi/vctk_gst_tacotron2&quot;, &quot;kan-bayashi/vctk_gst_transformer&quot;, &quot;kan-bayashi/vctk_xvector_tacotron2&quot;, &quot;kan-bayashi/vctk_xvector_transformer&quot;, &quot;kan-bayashi/vctk_xvector_conformer_fastspeech2&quot;, &quot;kan-bayashi/vctk_gst+xvector_tacotron2&quot;, &quot;kan-bayashi/vctk_gst+xvector_transformer&quot;, &quot;kan-bayashi/vctk_gst+xvector_conformer_fastspeech2&quot;, &quot;kan-bayashi/vctk_multi_spk_vits&quot;, &quot;kan-bayashi/vctk_full_band_multi_spk_vits&quot;, &quot;kan-bayashi/libritts_xvector_transformer&quot;, &quot;kan-bayashi/libritts_xvector_conformer_fastspeech2&quot;, &quot;kan-bayashi/libritts_gst+xvector_transformer&quot;, &quot;kan-bayashi/libritts_gst+xvector_conformer_fastspeech2&quot;, &quot;kan-bayashi/libritts_xvector_vits&quot;] {type:&quot;string&quot;}</span></span>
<span class="line"><span>vocoder_tag = &quot;none&quot; #@param [&quot;none&quot;, &quot;parallel_wavegan/vctk_parallel_wavegan.v1.long&quot;, &quot;parallel_wavegan/vctk_multi_band_melgan.v2&quot;, &quot;parallel_wavegan/vctk_style_melgan.v1&quot;, &quot;parallel_wavegan/vctk_hifigan.v1&quot;, &quot;parallel_wavegan/libritts_parallel_wavegan.v1.long&quot;, &quot;parallel_wavegan/libritts_multi_band_melgan.v2&quot;, &quot;parallel_wavegan/libritts_hifigan.v1&quot;, &quot;parallel_wavegan/libritts_style_melgan.v1&quot;] {type:&quot;string&quot;}</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="model-setup-1" tabindex="-1"><a class="header-anchor" href="#model-setup-1"><span>Model Setup</span></a></h3><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>from espnet2.bin.tts_inference import Text2Speech</span></span>
<span class="line"><span>from espnet2.utils.types import str_or_none</span></span>
<span class="line"><span></span></span>
<span class="line"><span>text2speech = Text2Speech.from_pretrained(</span></span>
<span class="line"><span>    model_tag=str_or_none(tag),</span></span>
<span class="line"><span>    vocoder_tag=str_or_none(vocoder_tag),</span></span>
<span class="line"><span>    device=&quot;cuda&quot;,</span></span>
<span class="line"><span>    # Only for Tacotron 2 &amp; Transformer</span></span>
<span class="line"><span>    threshold=0.5,</span></span>
<span class="line"><span>    # Only for Tacotron 2</span></span>
<span class="line"><span>    minlenratio=0.0,</span></span>
<span class="line"><span>    maxlenratio=10.0,</span></span>
<span class="line"><span>    use_att_constraint=False,</span></span>
<span class="line"><span>    backward_window=1,</span></span>
<span class="line"><span>    forward_window=3,</span></span>
<span class="line"><span>    # Only for FastSpeech &amp; FastSpeech2 &amp; VITS</span></span>
<span class="line"><span>    speed_control_alpha=1.0,</span></span>
<span class="line"><span>    # Only for VITS</span></span>
<span class="line"><span>    noise_scale=0.333,</span></span>
<span class="line"><span>    noise_scale_dur=0.333,</span></span>
<span class="line"><span>)</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="speaker-selection" tabindex="-1"><a class="header-anchor" href="#speaker-selection"><span>Speaker selection</span></a></h3><p>For multi-speaker model, we need to provide X-vector and/or the reference speech to decide the speaker characteristics.<br> For X-vector, you can select the speaker from the dumped x-vectors.<br> For the reference speech, you can use any speech but please make sure the sampling rate is matched.</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>import glob</span></span>
<span class="line"><span>import os</span></span>
<span class="line"><span>import numpy as np</span></span>
<span class="line"><span>import kaldiio</span></span>
<span class="line"><span></span></span>
<span class="line"><span># Get model directory path</span></span>
<span class="line"><span>from espnet_model_zoo.downloader import ModelDownloader</span></span>
<span class="line"><span>d = ModelDownloader()</span></span>
<span class="line"><span>model_dir = os.path.dirname(d.download_and_unpack(tag)[&quot;train_config&quot;])</span></span>
<span class="line"><span></span></span>
<span class="line"><span># X-vector selection</span></span>
<span class="line"><span>spembs = None</span></span>
<span class="line"><span>if text2speech.use_spembs:</span></span>
<span class="line"><span>    xvector_ark = [p for p in glob.glob(f&quot;{model_dir}/../../dump/**/spk_xvector.ark&quot;, recursive=True) if &quot;tr&quot; in p][0]</span></span>
<span class="line"><span>    xvectors = {k: v for k, v in kaldiio.load_ark(xvector_ark)}</span></span>
<span class="line"><span>    spks = list(xvectors.keys())</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    # randomly select speaker</span></span>
<span class="line"><span>    random_spk_idx = np.random.randint(0, len(spks))</span></span>
<span class="line"><span>    spk = spks[random_spk_idx]</span></span>
<span class="line"><span>    spembs = xvectors[spk]</span></span>
<span class="line"><span>    print(f&quot;selected spk: {spk}&quot;)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># Speaker ID selection</span></span>
<span class="line"><span>sids = None</span></span>
<span class="line"><span>if text2speech.use_sids:</span></span>
<span class="line"><span>    spk2sid = glob.glob(f&quot;{model_dir}/../../dump/**/spk2sid&quot;, recursive=True)[0]</span></span>
<span class="line"><span>    with open(spk2sid) as f:</span></span>
<span class="line"><span>        lines = [line.strip() for line in f.readlines()]</span></span>
<span class="line"><span>    sid2spk = {int(line.split()[1]): line.split()[0] for line in lines}</span></span>
<span class="line"><span>    </span></span>
<span class="line"><span>    # randomly select speaker</span></span>
<span class="line"><span>    sids = np.array(np.random.randint(1, len(sid2spk)))</span></span>
<span class="line"><span>    spk = sid2spk[int(sids)]</span></span>
<span class="line"><span>    print(f&quot;selected spk: {spk}&quot;)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># Reference speech selection for GST</span></span>
<span class="line"><span>speech = None</span></span>
<span class="line"><span>if text2speech.use_speech:</span></span>
<span class="line"><span>    # you can change here to load your own reference speech</span></span>
<span class="line"><span>    # e.g.</span></span>
<span class="line"><span>    # import soundfile as sf</span></span>
<span class="line"><span>    # speech, fs = sf.read(&quot;/path/to/reference.wav&quot;)</span></span>
<span class="line"><span>    # speech = torch.from_numpy(speech).float()</span></span>
<span class="line"><span>    speech = torch.randn(50000,) * 0.01</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="synthesis-1" tabindex="-1"><a class="header-anchor" href="#synthesis-1"><span>Synthesis</span></a></h3><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="shiki dark-plus" style="background-color:#1E1E1E;color:#D4D4D4;" tabindex="0"><code><span class="line"><span>import time</span></span>
<span class="line"><span>import torch</span></span>
<span class="line"><span></span></span>
<span class="line"><span># decide the input sentence by yourself</span></span>
<span class="line"><span>print(f&quot;Input your favorite sentence in {lang}.&quot;)</span></span>
<span class="line"><span>x = input()</span></span>
<span class="line"><span></span></span>
<span class="line"><span># synthesis</span></span>
<span class="line"><span>with torch.no_grad():</span></span>
<span class="line"><span>    start = time.time()</span></span>
<span class="line"><span>    wav = text2speech(x, speech=speech, spembs=spembs, sids=sids)[&quot;wav&quot;]</span></span>
<span class="line"><span>rtf = (time.time() - start) / (len(wav) / text2speech.fs)</span></span>
<span class="line"><span>print(f&quot;RTF = {rtf:5f}&quot;)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># let us listen to generated samples</span></span>
<span class="line"><span>from IPython.display import display, Audio</span></span>
<span class="line"><span>display(Audio(wav.view(-1).cpu().numpy(), rate=text2speech.fs))</span></span>
<span class="line"><span></span></span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></div><!--[--><!--]--></div><footer class="page-meta"><!----><!----><!----></footer><nav class="page-nav" aria-label="page navigation"><p class="inner"><!----><span class="next"><a href="/notebook/espnet2/tts/tts_cli.html" class="" aria-label="Text-to-Speech (Recipe)"><!--[--><!--]--> Text-to-Speech (Recipe) <!--[--><!--]--></a></span></p></nav><!--[--><!--]--></main><!--]--></div><!----><!--]--></div>
    <script type="module" src="/notebook/assets/app-FOR18dDf.js" defer></script>
  </body>
</html>
